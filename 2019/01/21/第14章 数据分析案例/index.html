<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">
<script>
    (function () {
        if ('cyj') {
            if (prompt('请输入文章密码') !== 'cyj') {
                alert('密码错误！');
                if (history.length === 1) {
                    location.replace("https://janetcheng01.github.io/"); 
                } else {
                    history.back();
                }
            }
        }
    })();
</script>







<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />



  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">






  <meta name="keywords" content="数据分析,Python教程," />





  <link rel="alternate" href="/atom.xml" title="Janet blog" type="application/atom+xml" />






<meta name="description" content="正文的最后一章，我们来看一些真实世界的数据集。对于每个数据集，我们会用之前介绍的方法，从原始数据中提取有意义的内容。">
<meta name="keywords" content="数据分析,Python教程">
<meta property="og:type" content="article">
<meta property="og:title" content="第14章 数据分析案例">
<meta property="og:url" content="http://yoursite.com/2019/01/21/第14章 数据分析案例/index.html">
<meta property="og:site_name" content="Janet blog">
<meta property="og:description" content="正文的最后一章，我们来看一些真实世界的数据集。对于每个数据集，我们会用之前介绍的方法，从原始数据中提取有意义的内容。">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/7178691-aa267c1d399a78f0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/7178691-053612a5655b68d9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/7178691-60ee355801daf412.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/7178691-7643b150d88aae11.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/7178691-33f0f97656367a53.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/7178691-63e1ddc326a033b9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/7178691-574b53a383cad681.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/7178691-67686f38e66ef5f1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/7178691-51c431b2490424c2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/7178691-b99d98f8bb5fc695.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/7178691-99b176d022a444c0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/7178691-d2254e547c6ce537.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:image" content="http://upload-images.jianshu.io/upload_images/7178691-77e8c8d3c784692b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">
<meta property="og:updated_time" content="2019-03-27T04:04:26.418Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="第14章 数据分析案例">
<meta name="twitter:description" content="正文的最后一章，我们来看一些真实世界的数据集。对于每个数据集，我们会用之前介绍的方法，从原始数据中提取有意义的内容。">
<meta name="twitter:image" content="http://upload-images.jianshu.io/upload_images/7178691-aa267c1d399a78f0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2019/01/21/第14章 数据分析案例/"/>





  <title>第14章 数据分析案例 | Janet blog</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Janet blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">横看成岭侧成峰，远近高低各不同。Be curious always!</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/01/21/第14章 数据分析案例/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Janet">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Janet blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">第14章 数据分析案例</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-01-21T00:00:00+08:00">
                2019-01-21
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/工具案例/" itemprop="url" rel="index">
                    <span itemprop="name">工具案例</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/工具案例/Python/" itemprop="url" rel="index">
                    <span itemprop="name">Python</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  11.6k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  56
                </span>
              
            </div>
          

          
              <div class="post-description">
                  正文的最后一章，我们来看一些真实世界的数据集。对于每个数据集，我们会用之前介绍的方法，从原始数据中提取有意义的内容。
              </div>
          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>本书正文的最后一章，我们来看一些真实世界的数据集。对于每个数据集，我们会用之前介绍的方法，从原始数据中提取有意义的内容。展示的方法适用于其它数据集，也包括你的。本章包含了一些各种各样的案例数据集，可以用来练习。</p>
<p>案例数据集可以在Github仓库找到，见第一章。</p>
<p>#14.1 来自Bitly的USA.gov数据</p>
<p>2011年，URL缩短服务Bitly跟美国政府网站USA.gov合作，提供了一份从生成.gov或.mil短链接的用户那里收集来的匿名数据。在2011年，除实时数据之外，还可以下载文本文件形式的每小时快照。写作此书时（2017年），这项服务已经关闭，但我们保存一份数据用于本书的案例。</p>
<p>以每小时快照为例，文件中各行的格式为JSON（即JavaScript Object Notation，这是一种常用的Web数据格式）。例如，如果我们只读取某个文件中的第一行，那么所看到的结果应该是下面这样：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">5</span>]: path = <span class="string">'datasets/bitly_usagov/example.txt'</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">6</span>]: open(path).readline()</span><br><span class="line">Out[<span class="number">6</span>]: <span class="string">'&#123; "a": "Mozilla\\/5.0 (Windows NT 6.1; WOW64) AppleWebKit\\/535.11</span></span><br><span class="line"><span class="string">(KHTML, like Gecko) Chrome\\/17.0.963.78 Safari\\/535.11", "c": "US", "nk": 1,</span></span><br><span class="line"><span class="string">"tz": "America\\/New_York", "gr": "MA", "g": "A6qOVH", "h": "wfLQtf", "l":</span></span><br><span class="line"><span class="string">"orofrog", "al": "en-US,en;q=0.8", "hh": "1.usa.gov", "r":</span></span><br><span class="line"><span class="string">"http:\\/\\/www.facebook.com\\/l\\/7AQEFzjSi\\/1.usa.gov\\/wfLQtf", "u":</span></span><br><span class="line"><span class="string">"http:\\/\\/www.ncbi.nlm.nih.gov\\/pubmed\\/22415991", "t": 1331923247, "hc":</span></span><br><span class="line"><span class="string">1331822918, "cy": "Danvers", "ll": [ 42.576698, -70.954903 ] &#125;\n'</span></span><br></pre></td></tr></table></figure></p>
<p>Python有内置或第三方模块可以将JSON字符串转换成Python字典对象。这里，我将使用json模块及其loads函数逐行加载已经下载好的数据文件：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line">path = <span class="string">'datasets/bitly_usagov/example.txt'</span></span><br><span class="line">records = [json.loads(line) <span class="keyword">for</span> line <span class="keyword">in</span> open(path)]</span><br></pre></td></tr></table></figure></p>
<p>现在，records对象就成为一组Python字典了：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">18</span>]: records[<span class="number">0</span>]</span><br><span class="line">Out[<span class="number">18</span>]:</span><br><span class="line">&#123;<span class="string">'a'</span>: <span class="string">'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.11 (KHTML, like Gecko)</span></span><br><span class="line"><span class="string">Chrome/17.0.963.78 Safari/535.11'</span>,</span><br><span class="line"> <span class="string">'al'</span>: <span class="string">'en-US,en;q=0.8'</span>,</span><br><span class="line"> <span class="string">'c'</span>: <span class="string">'US'</span>,</span><br><span class="line"> <span class="string">'cy'</span>: <span class="string">'Danvers'</span>,</span><br><span class="line"> <span class="string">'g'</span>: <span class="string">'A6qOVH'</span>,</span><br><span class="line"> <span class="string">'gr'</span>: <span class="string">'MA'</span>,</span><br><span class="line"> <span class="string">'h'</span>: <span class="string">'wfLQtf'</span>,</span><br><span class="line"> <span class="string">'hc'</span>: <span class="number">1331822918</span>,</span><br><span class="line"> <span class="string">'hh'</span>: <span class="string">'1.usa.gov'</span>,</span><br><span class="line"> <span class="string">'l'</span>: <span class="string">'orofrog'</span>,</span><br><span class="line"> <span class="string">'ll'</span>: [<span class="number">42.576698</span>, <span class="number">-70.954903</span>],</span><br><span class="line"> <span class="string">'nk'</span>: <span class="number">1</span>,</span><br><span class="line"> <span class="string">'r'</span>: <span class="string">'http://www.facebook.com/l/7AQEFzjSi/1.usa.gov/wfLQtf'</span>,</span><br><span class="line"> <span class="string">'t'</span>: <span class="number">1331923247</span>,</span><br><span class="line"> <span class="string">'tz'</span>: <span class="string">'America/New_York'</span>,</span><br><span class="line"> <span class="string">'u'</span>: <span class="string">'http://www.ncbi.nlm.nih.gov/pubmed/22415991'</span>&#125;</span><br></pre></td></tr></table></figure></p>
<p>##用纯Python代码对时区进行计数</p>
<p>假设我们想要知道该数据集中最常出现的是哪个时区（即tz字段），得到答案的办法有很多。首先，我们用列表推导式取出一组时区：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">12</span>]: time_zones = [rec[<span class="string">'tz'</span>] <span class="keyword">for</span> rec <span class="keyword">in</span> records]</span><br><span class="line">---------------------------------------------------------------------------</span><br><span class="line">KeyError                                  Traceback (most recent call last)</span><br><span class="line">&lt;ipython-input<span class="number">-12</span>-db4fbd348da9&gt; <span class="keyword">in</span> &lt;module&gt;()</span><br><span class="line">----&gt; 1 time_zones = [rec['tz'] for rec in records]</span><br><span class="line">&lt;ipython-input<span class="number">-12</span>-db4fbd348da9&gt; <span class="keyword">in</span> &lt;listcomp&gt;(<span class="number">.0</span>)</span><br><span class="line">----&gt; 1 time_zones = [rec['tz'] for rec in records]</span><br><span class="line">KeyError: <span class="string">'tz'</span></span><br></pre></td></tr></table></figure></p>
<p>晕！原来并不是所有记录都有时区字段。这个好办，只需在列表推导式末尾加上一个if ‘tz’in rec判断即可：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">13</span>]: time_zones = [rec[<span class="string">'tz'</span>] <span class="keyword">for</span> rec <span class="keyword">in</span> records <span class="keyword">if</span> <span class="string">'tz'</span> <span class="keyword">in</span> rec]</span><br><span class="line"></span><br><span class="line">In [<span class="number">14</span>]: time_zones[:<span class="number">10</span>]</span><br><span class="line">Out[<span class="number">14</span>]: </span><br><span class="line">[<span class="string">'America/New_York'</span>,</span><br><span class="line"> <span class="string">'America/Denver'</span>,</span><br><span class="line"> <span class="string">'America/New_York'</span>,</span><br><span class="line"> <span class="string">'America/Sao_Paulo'</span>,</span><br><span class="line"> <span class="string">'America/New_York'</span>,</span><br><span class="line"> <span class="string">'America/New_York'</span>,</span><br><span class="line"> <span class="string">'Europe/Warsaw'</span>,</span><br><span class="line"> <span class="string">''</span>,</span><br><span class="line"> <span class="string">''</span>,</span><br><span class="line"> <span class="string">''</span>]</span><br></pre></td></tr></table></figure></p>
<p>只看前10个时区，我们发现有些是未知的（即空的）。虽然可以将它们过滤掉，但现在暂时先留着。接下来，为了对时区进行计数，这里介绍两个办法：一个较难（只使用标准Python库），另一个较简单（使用pandas）。计数的办法之一是在遍历时区的过程中将计数值保存在字典中：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_counts</span><span class="params">(sequence)</span>:</span></span><br><span class="line">    counts = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> sequence:</span><br><span class="line">        <span class="keyword">if</span> x <span class="keyword">in</span> counts:</span><br><span class="line">            counts[x] += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            counts[x] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> counts</span><br></pre></td></tr></table></figure></p>
<p>如果使用Python标准库的更高级工具，那么你可能会将代码写得更简洁一些：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_counts2</span><span class="params">(sequence)</span>:</span></span><br><span class="line">    counts = defaultdict(int) <span class="comment"># values will initialize to 0</span></span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> sequence:</span><br><span class="line">        counts[x] += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> counts</span><br></pre></td></tr></table></figure></p>
<p>我将逻辑写到函数中是为了获得更高的复用性。要用它对时区进行处理，只需将time_zones传入即可：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">17</span>]: counts = get_counts(time_zones)</span><br><span class="line"></span><br><span class="line">In [<span class="number">18</span>]: counts[<span class="string">'America/New_York'</span>]</span><br><span class="line">Out[<span class="number">18</span>]: <span class="number">1251</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">19</span>]: len(time_zones)</span><br><span class="line">Out[<span class="number">19</span>]: <span class="number">3440</span></span><br></pre></td></tr></table></figure></p>
<p>如果想要得到前10位的时区及其计数值，我们需要用到一些有关字典的处理技巧：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">top_counts</span><span class="params">(count_dict, n=<span class="number">10</span>)</span>:</span></span><br><span class="line">    value_key_pairs = [(count, tz) <span class="keyword">for</span> tz, count <span class="keyword">in</span> count_dict.items()]</span><br><span class="line">    value_key_pairs.sort()</span><br><span class="line">    <span class="keyword">return</span> value_key_pairs[-n:]</span><br></pre></td></tr></table></figure></p>
<p>然后有：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">21</span>]: top_counts(counts)</span><br><span class="line">Out[<span class="number">21</span>]: </span><br><span class="line">[(<span class="number">33</span>, <span class="string">'America/Sao_Paulo'</span>),</span><br><span class="line"> (<span class="number">35</span>, <span class="string">'Europe/Madrid'</span>),</span><br><span class="line">(<span class="number">36</span>, <span class="string">'Pacific/Honolulu'</span>),</span><br><span class="line"> (<span class="number">37</span>, <span class="string">'Asia/Tokyo'</span>),</span><br><span class="line"> (<span class="number">74</span>, <span class="string">'Europe/London'</span>),</span><br><span class="line"> (<span class="number">191</span>, <span class="string">'America/Denver'</span>),</span><br><span class="line"> (<span class="number">382</span>, <span class="string">'America/Los_Angeles'</span>),</span><br><span class="line"> (<span class="number">400</span>, <span class="string">'America/Chicago'</span>),</span><br><span class="line"> (<span class="number">521</span>, <span class="string">''</span>),</span><br><span class="line"> (<span class="number">1251</span>, <span class="string">'America/New_York'</span>)]</span><br></pre></td></tr></table></figure></p>
<p>如果你搜索Python的标准库，你能找到collections.Counter类，它可以使这项工作更简单：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">22</span>]: <span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"></span><br><span class="line">In [<span class="number">23</span>]: counts = Counter(time_zones)</span><br><span class="line"></span><br><span class="line">In [<span class="number">24</span>]: counts.most_common(<span class="number">10</span>)</span><br><span class="line">Out[<span class="number">24</span>]: </span><br><span class="line">[(<span class="string">'America/New_York'</span>, <span class="number">1251</span>),</span><br><span class="line"> (<span class="string">''</span>, <span class="number">521</span>),</span><br><span class="line"> (<span class="string">'America/Chicago'</span>, <span class="number">400</span>),</span><br><span class="line"> (<span class="string">'America/Los_Angeles'</span>, <span class="number">382</span>),</span><br><span class="line"> (<span class="string">'America/Denver'</span>, <span class="number">191</span>),</span><br><span class="line"> (<span class="string">'Europe/London'</span>, <span class="number">74</span>),</span><br><span class="line"> (<span class="string">'Asia/Tokyo'</span>, <span class="number">37</span>),</span><br><span class="line"> (<span class="string">'Pacific/Honolulu'</span>, <span class="number">36</span>),</span><br><span class="line"> (<span class="string">'Europe/Madrid'</span>, <span class="number">35</span>),</span><br><span class="line"> (<span class="string">'America/Sao_Paulo'</span>, <span class="number">33</span>)]</span><br></pre></td></tr></table></figure></p>
<h2 id="用pandas对时区进行计数"><a href="#用pandas对时区进行计数" class="headerlink" title="用pandas对时区进行计数"></a>用pandas对时区进行计数</h2><p>从原始记录的集合创建DateFrame，与将记录列表传递到pandas.DataFrame一样简单：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">25</span>]: <span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">In [<span class="number">26</span>]: frame = pd.DataFrame(records)</span><br><span class="line"></span><br><span class="line">In [<span class="number">27</span>]: frame.info()</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">pandas</span>.<span class="title">core</span>.<span class="title">frame</span>.<span class="title">DataFrame</span>'&gt;</span></span><br><span class="line"><span class="class"><span class="title">RangeIndex</span>:</span> <span class="number">3560</span> entries, <span class="number">0</span> to <span class="number">3559</span></span><br><span class="line">Data columns (total <span class="number">18</span> columns):</span><br><span class="line">_heartbeat_    <span class="number">120</span> non-null float64</span><br><span class="line">a              <span class="number">3440</span> non-null object</span><br><span class="line">al             <span class="number">3094</span> non-null object</span><br><span class="line">c              <span class="number">2919</span> non-null object</span><br><span class="line">cy             <span class="number">2919</span> non-null object</span><br><span class="line">g              <span class="number">3440</span> non-null object</span><br><span class="line">gr             <span class="number">2919</span> non-null object</span><br><span class="line">h              <span class="number">3440</span> non-null object</span><br><span class="line">hc             <span class="number">3440</span> non-null float64</span><br><span class="line">hh             <span class="number">3440</span> non-null object</span><br><span class="line">kw             <span class="number">93</span> non-null object</span><br><span class="line">l              <span class="number">3440</span> non-null object</span><br><span class="line">ll             <span class="number">2919</span> non-null object</span><br><span class="line">nk             <span class="number">3440</span> non-null float64</span><br><span class="line">r              <span class="number">3440</span> non-null object</span><br><span class="line">t              <span class="number">3440</span> non-null float64</span><br><span class="line">tz             <span class="number">3440</span> non-null object</span><br><span class="line">u              <span class="number">3440</span> non-null object</span><br><span class="line">dtypes: float64(<span class="number">4</span>), object(<span class="number">14</span>)</span><br><span class="line">memory usage: <span class="number">500.7</span>+ KB</span><br><span class="line"></span><br><span class="line">In [<span class="number">28</span>]: frame[<span class="string">'tz'</span>][:<span class="number">10</span>]</span><br><span class="line">Out[<span class="number">28</span>]: </span><br><span class="line"><span class="number">0</span>     America/New_York</span><br><span class="line"><span class="number">1</span>       America/Denver</span><br><span class="line"><span class="number">2</span>     America/New_York</span><br><span class="line"><span class="number">3</span>    America/Sao_Paulo</span><br><span class="line"><span class="number">4</span>     America/New_York</span><br><span class="line"><span class="number">5</span>     America/New_York</span><br><span class="line"><span class="number">6</span>        Europe/Warsaw</span><br><span class="line"><span class="number">7</span>                     </span><br><span class="line"><span class="number">8</span>                     </span><br><span class="line"><span class="number">9</span>                     </span><br><span class="line">Name: tz, dtype: object</span><br></pre></td></tr></table></figure></p>
<p>这里frame的输出形式是摘要视图（summary view），主要用于较大的DataFrame对象。我们然后可以对Series使用value_counts方法：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">29</span>]: tz_counts = frame[<span class="string">'tz'</span>].value_counts()</span><br><span class="line"></span><br><span class="line">In [<span class="number">30</span>]: tz_counts[:<span class="number">10</span>]</span><br><span class="line">Out[<span class="number">30</span>]: </span><br><span class="line">America/New_York       <span class="number">1251</span></span><br><span class="line">                        <span class="number">521</span></span><br><span class="line">America/Chicago         <span class="number">400</span></span><br><span class="line">America/Los_Angeles     <span class="number">382</span></span><br><span class="line">America/Denver          <span class="number">191</span></span><br><span class="line">Europe/London            <span class="number">74</span></span><br><span class="line">Asia/Tokyo               <span class="number">37</span></span><br><span class="line">Pacific/Honolulu         <span class="number">36</span></span><br><span class="line">Europe/Madrid            <span class="number">35</span></span><br><span class="line">America/Sao_Paulo        <span class="number">33</span></span><br><span class="line">Name: tz, dtype: int64</span><br></pre></td></tr></table></figure></p>
<p>我们可以用matplotlib可视化这个数据。为此，我们先给记录中未知或缺失的时区填上一个替代值。fillna函数可以替换缺失值（NA），而未知值（空字符串）则可以通过布尔型数组索引加以替换：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">31</span>]: clean_tz = frame[<span class="string">'tz'</span>].fillna(<span class="string">'Missing'</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">32</span>]: clean_tz[clean_tz == <span class="string">''</span>] = <span class="string">'Unknown'</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">33</span>]: tz_counts = clean_tz.value_counts()</span><br><span class="line"></span><br><span class="line">In [<span class="number">34</span>]: tz_counts[:<span class="number">10</span>]</span><br><span class="line">Out[<span class="number">34</span>]: </span><br><span class="line">America/New_York       <span class="number">1251</span></span><br><span class="line">Unknown                 <span class="number">521</span></span><br><span class="line">America/Chicago         <span class="number">400</span></span><br><span class="line">America/Los_Angeles     <span class="number">382</span></span><br><span class="line">America/Denver          <span class="number">191</span></span><br><span class="line">Missing                 <span class="number">120</span></span><br><span class="line">Europe/London            <span class="number">74</span></span><br><span class="line">Asia/Tokyo               <span class="number">37</span></span><br><span class="line">Pacific/Honolulu         <span class="number">36</span></span><br><span class="line">Europe/Madrid            <span class="number">35</span></span><br><span class="line">Name: tz, dtype: int64</span><br></pre></td></tr></table></figure></p>
<p>此时，我们可以用seaborn包创建水平柱状图（结果见图14-1）：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">36</span>]: <span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line">In [<span class="number">37</span>]: subset = tz_counts[:<span class="number">10</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">38</span>]: sns.barplot(y=subset.index, x=subset.values)</span><br></pre></td></tr></table></figure></p>
<p><img src="http://upload-images.jianshu.io/upload_images/7178691-aa267c1d399a78f0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图14-1 usa.gov示例数据中最常出现的时区"></p>
<p>a字段含有执行URL短缩操作的浏览器、设备、应用程序的相关信息：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">39</span>]: frame[<span class="string">'a'</span>][<span class="number">1</span>]</span><br><span class="line">Out[<span class="number">39</span>]: <span class="string">'GoogleMaps/RochesterNY'</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">40</span>]: frame[<span class="string">'a'</span>][<span class="number">50</span>]</span><br><span class="line">Out[<span class="number">40</span>]: <span class="string">'Mozilla/5.0 (Windows NT 5.1; rv:10.0.2)</span></span><br><span class="line"><span class="string">Gecko/20100101 Firefox/10.0.2'</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">41</span>]: frame[<span class="string">'a'</span>][<span class="number">51</span>][:<span class="number">50</span>]  <span class="comment"># long line</span></span><br><span class="line">Out[<span class="number">41</span>]: <span class="string">'Mozilla/5.0 (Linux; U; Android 2.2.2; en-us; LG-P9'</span></span><br></pre></td></tr></table></figure></p>
<p>将这些”agent”字符串中的所有信息都解析出来是一件挺郁闷的工作。一种策略是将这种字符串的第一节（与浏览器大致对应）分离出来并得到另外一份用户行为摘要：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">42</span>]: results = pd.Series([x.split()[<span class="number">0</span>] <span class="keyword">for</span> x <span class="keyword">in</span> frame.a.dropna()])</span><br><span class="line"></span><br><span class="line">In [<span class="number">43</span>]: results[:<span class="number">5</span>]</span><br><span class="line">Out[<span class="number">43</span>]: </span><br><span class="line"><span class="number">0</span>               Mozilla/<span class="number">5.0</span></span><br><span class="line"><span class="number">1</span>    GoogleMaps/RochesterNY</span><br><span class="line"><span class="number">2</span>               Mozilla/<span class="number">4.0</span></span><br><span class="line"><span class="number">3</span>               Mozilla/<span class="number">5.0</span></span><br><span class="line"><span class="number">4</span>               Mozilla/<span class="number">5.0</span></span><br><span class="line">dtype: object</span><br><span class="line"></span><br><span class="line">In [<span class="number">44</span>]: results.value_counts()[:<span class="number">8</span>]</span><br><span class="line">Out[<span class="number">44</span>]: </span><br><span class="line">Mozilla/<span class="number">5.0</span>                 <span class="number">2594</span></span><br><span class="line">Mozilla/<span class="number">4.0</span>                  <span class="number">601</span></span><br><span class="line">GoogleMaps/RochesterNY       <span class="number">121</span></span><br><span class="line">Opera/<span class="number">9.80</span>                    <span class="number">34</span></span><br><span class="line">TEST_INTERNET_AGENT           <span class="number">24</span></span><br><span class="line">GoogleProducer                <span class="number">21</span></span><br><span class="line">Mozilla/<span class="number">6.0</span>                    <span class="number">5</span></span><br><span class="line">BlackBerry8520/<span class="number">5.0</span><span class="number">.0</span><span class="number">.681</span>       <span class="number">4</span></span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure></p>
<p>现在，假设你想按Windows和非Windows用户对时区统计信息进行分解。为了简单起见，我们假定只要agent字符串中含有”Windows”就认为该用户为Windows用户。由于有的agent缺失，所以首先将它们从数据中移除：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">45</span>]: cframe = frame[frame.a.notnull()]</span><br></pre></td></tr></table></figure></p>
<p>然后计算出各行是否含有Windows的值：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">47</span>]: cframe[<span class="string">'os'</span>] = np.where(cframe[<span class="string">'a'</span>].str.contains(<span class="string">'Windows'</span>),</span><br><span class="line">   ....:                         <span class="string">'Windows'</span>, <span class="string">'Not Windows'</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">48</span>]: cframe[<span class="string">'os'</span>][:<span class="number">5</span>]</span><br><span class="line">Out[<span class="number">48</span>]: </span><br><span class="line"><span class="number">0</span>        Windows</span><br><span class="line"><span class="number">1</span>    Not Windows</span><br><span class="line"><span class="number">2</span>        Windows</span><br><span class="line"><span class="number">3</span>    Not Windows</span><br><span class="line"><span class="number">4</span>        Windows</span><br><span class="line">Name: os, dtype: object</span><br></pre></td></tr></table></figure></p>
<p>接下来就可以根据时区和新得到的操作系统列表对数据进行分组了：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">49</span>]: by_tz_os = cframe.groupby([<span class="string">'tz'</span>, <span class="string">'os'</span>])</span><br></pre></td></tr></table></figure></p>
<p>分组计数，类似于value_counts函数，可以用size来计算。并利用unstack对计数结果进行重塑：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">50</span>]: agg_counts = by_tz_os.size().unstack().fillna(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">51</span>]: agg_counts[:<span class="number">10</span>]</span><br><span class="line">Out[<span class="number">51</span>]: </span><br><span class="line">os                              Not Windows  Windows</span><br><span class="line">tz                                                  </span><br><span class="line">                                      <span class="number">245.0</span>    <span class="number">276.0</span></span><br><span class="line">Africa/Cairo                            <span class="number">0.0</span>      <span class="number">3.0</span></span><br><span class="line">Africa/Casablanca                       <span class="number">0.0</span>      <span class="number">1.0</span></span><br><span class="line">Africa/Ceuta                            <span class="number">0.0</span>      <span class="number">2.0</span></span><br><span class="line">Africa/Johannesburg                     <span class="number">0.0</span>      <span class="number">1.0</span></span><br><span class="line">Africa/Lusaka                           <span class="number">0.0</span>      <span class="number">1.0</span></span><br><span class="line">America/Anchorage                       <span class="number">4.0</span>      <span class="number">1.0</span></span><br><span class="line">America/Argentina/Buenos_Aires          <span class="number">1.0</span>      <span class="number">0.0</span></span><br><span class="line">America/Argentina/Cordoba               <span class="number">0.0</span>      <span class="number">1.0</span></span><br><span class="line">America/Argentina/Mendoza               <span class="number">0.0</span>      <span class="number">1.0</span></span><br></pre></td></tr></table></figure></p>
<p>最后，我们来选取最常出现的时区。为了达到这个目的，我根据agg_counts中的行数构造了一个间接索引数组：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Use to sort in ascending order</span></span><br><span class="line">In [<span class="number">52</span>]: indexer = agg_counts.sum(<span class="number">1</span>).argsort()</span><br><span class="line"></span><br><span class="line">In [<span class="number">53</span>]: indexer[:<span class="number">10</span>]</span><br><span class="line">Out[<span class="number">53</span>]: </span><br><span class="line">tz</span><br><span class="line">                                  <span class="number">24</span></span><br><span class="line">Africa/Cairo                      <span class="number">20</span></span><br><span class="line">Africa/Casablanca                 <span class="number">21</span></span><br><span class="line">Africa/Ceuta                      <span class="number">92</span></span><br><span class="line">Africa/Johannesburg               <span class="number">87</span></span><br><span class="line">Africa/Lusaka                     <span class="number">53</span></span><br><span class="line">America/Anchorage                 <span class="number">54</span></span><br><span class="line">America/Argentina/Buenos_Aires    <span class="number">57</span></span><br><span class="line">America/Argentina/Cordoba         <span class="number">26</span></span><br><span class="line">America/Argentina/Mendoza         <span class="number">55</span></span><br><span class="line">dtype: int64</span><br></pre></td></tr></table></figure></p>
<p>然后我通过take按照这个顺序截取了最后10行最大值：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">54</span>]: count_subset = agg_counts.take(indexer[<span class="number">-10</span>:])</span><br><span class="line"></span><br><span class="line">In [<span class="number">55</span>]: count_subset</span><br><span class="line">Out[<span class="number">55</span>]: </span><br><span class="line">os                   Not Windows  Windows</span><br><span class="line">tz                                       </span><br><span class="line">America/Sao_Paulo           <span class="number">13.0</span>     <span class="number">20.0</span></span><br><span class="line">Europe/Madrid               <span class="number">16.0</span>     <span class="number">19.0</span></span><br><span class="line">Pacific/Honolulu             <span class="number">0.0</span>     <span class="number">36.0</span></span><br><span class="line">Asia/Tokyo                   <span class="number">2.0</span>     <span class="number">35.0</span></span><br><span class="line">Europe/London               <span class="number">43.0</span>     <span class="number">31.0</span></span><br><span class="line">America/Denver             <span class="number">132.0</span>     <span class="number">59.0</span></span><br><span class="line">America/Los_Angeles        <span class="number">130.0</span>    <span class="number">252.0</span></span><br><span class="line">America/Chicago            <span class="number">115.0</span>    <span class="number">285.0</span></span><br><span class="line">                           <span class="number">245.0</span>    <span class="number">276.0</span></span><br><span class="line">America/New_York           <span class="number">339.0</span>    <span class="number">912.0</span></span><br></pre></td></tr></table></figure></p>
<p>pandas有一个简便方法nlargest，可以做同样的工作：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">56</span>]: agg_counts.sum(<span class="number">1</span>).nlargest(<span class="number">10</span>)</span><br><span class="line">Out[<span class="number">56</span>]: </span><br><span class="line">tz</span><br><span class="line">America/New_York       <span class="number">1251.0</span></span><br><span class="line">                        <span class="number">521.0</span></span><br><span class="line">America/Chicago         <span class="number">400.0</span></span><br><span class="line">America/Los_Angeles     <span class="number">382.0</span></span><br><span class="line">America/Denver          <span class="number">191.0</span></span><br><span class="line">Europe/London            <span class="number">74.0</span></span><br><span class="line">Asia/Tokyo               <span class="number">37.0</span></span><br><span class="line">Pacific/Honolulu         <span class="number">36.0</span></span><br><span class="line">Europe/Madrid            <span class="number">35.0</span></span><br><span class="line">America/Sao_Paulo        <span class="number">33.0</span></span><br><span class="line">dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>然后，如这段代码所示，可以用柱状图表示。我传递一个额外参数到seaborn的barpolt函数，来画一个堆积条形图（见图14-2）：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Rearrange the data for plotting</span></span><br><span class="line">In [<span class="number">58</span>]: count_subset = count_subset.stack()</span><br><span class="line"></span><br><span class="line">In [<span class="number">59</span>]: count_subset.name = <span class="string">'total'</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">60</span>]: count_subset = count_subset.reset_index()</span><br><span class="line"></span><br><span class="line">In [<span class="number">61</span>]: count_subset[:<span class="number">10</span>]</span><br><span class="line">Out[<span class="number">61</span>]: </span><br><span class="line">                  tz           os  total</span><br><span class="line"><span class="number">0</span>  America/Sao_Paulo  Not Windows   <span class="number">13.0</span></span><br><span class="line"><span class="number">1</span>  America/Sao_Paulo      Windows   <span class="number">20.0</span></span><br><span class="line"><span class="number">2</span>      Europe/Madrid  Not Windows   <span class="number">16.0</span></span><br><span class="line"><span class="number">3</span>      Europe/Madrid      Windows   <span class="number">19.0</span></span><br><span class="line"><span class="number">4</span>   Pacific/Honolulu  Not Windows    <span class="number">0.0</span></span><br><span class="line"><span class="number">5</span>   Pacific/Honolulu      Windows   <span class="number">36.0</span></span><br><span class="line"><span class="number">6</span>         Asia/Tokyo  Not Windows    <span class="number">2.0</span></span><br><span class="line"><span class="number">7</span>         Asia/Tokyo      Windows   <span class="number">35.0</span></span><br><span class="line"><span class="number">8</span>      Europe/London  Not Windows   <span class="number">43.0</span></span><br><span class="line"><span class="number">9</span>      Europe/London      Windows   <span class="number">31.0</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">62</span>]: sns.barplot(x=<span class="string">'total'</span>, y=<span class="string">'tz'</span>, hue=<span class="string">'os'</span>,  data=count_subset)</span><br></pre></td></tr></table></figure></p>
<p><img src="http://upload-images.jianshu.io/upload_images/7178691-053612a5655b68d9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图14-2 最常出现时区的Windows和非Windows用户"></p>
<p>这张图不容易看出Windows用户在小分组中的相对比例，因此标准化分组百分比之和为1：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">norm_total</span><span class="params">(group)</span>:</span></span><br><span class="line">    group[<span class="string">'normed_total'</span>] = group.total / group.total.sum()</span><br><span class="line">    <span class="keyword">return</span> group</span><br><span class="line"></span><br><span class="line">results = count_subset.groupby(<span class="string">'tz'</span>).apply(norm_total)</span><br></pre></td></tr></table></figure></p>
<p>再次画图，见图14-3：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">65</span>]: sns.barplot(x=<span class="string">'normed_total'</span>, y=<span class="string">'tz'</span>, hue=<span class="string">'os'</span>,  data=results)</span><br></pre></td></tr></table></figure></p>
<p><img src="http://upload-images.jianshu.io/upload_images/7178691-60ee355801daf412.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图14-3 最常出现时区的Windows和非Windows用户的百分比"></p>
<p>我们还可以用groupby的transform方法，更高效的计算标准化的和：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">66</span>]: g = count_subset.groupby(<span class="string">'tz'</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">67</span>]: results2 = count_subset.total / g.total.transform(<span class="string">'sum'</span>)</span><br></pre></td></tr></table></figure></p>
<h1 id="14-2-MovieLens-1M数据集"><a href="#14-2-MovieLens-1M数据集" class="headerlink" title="14.2 MovieLens 1M数据集"></a>14.2 MovieLens 1M数据集</h1><p>GroupLens Research（<a href="http://www.grouplens.org/node/73）采集了一组从20世纪90年末到21世纪初由MovieLens用户提供的电影评分数据。这些数据中包括电影评分、电影元数据（风格类型和年代）以及关于用户的人口统计学数据（年龄、邮编、性别和职业等）。基于机器学习算法的推荐系统一般都会对此类数据感兴趣。虽然我不会在本书中详细介绍机器学习技术，但我会告诉你如何对这种数据进行切片切块以满足实际需求。" target="_blank" rel="noopener">http://www.grouplens.org/node/73）采集了一组从20世纪90年末到21世纪初由MovieLens用户提供的电影评分数据。这些数据中包括电影评分、电影元数据（风格类型和年代）以及关于用户的人口统计学数据（年龄、邮编、性别和职业等）。基于机器学习算法的推荐系统一般都会对此类数据感兴趣。虽然我不会在本书中详细介绍机器学习技术，但我会告诉你如何对这种数据进行切片切块以满足实际需求。</a></p>
<p>MovieLens 1M数据集含有来自6000名用户对4000部电影的100万条评分数据。它分为三个表：评分、用户信息和电影信息。将该数据从zip文件中解压出来之后，可以通过pandas.read_table将各个表分别读到一个pandas DataFrame对象中：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># Make display smaller</span></span><br><span class="line">pd.options.display.max_rows = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">unames = [<span class="string">'user_id'</span>, <span class="string">'gender'</span>, <span class="string">'age'</span>, <span class="string">'occupation'</span>, <span class="string">'zip'</span>]</span><br><span class="line">users = pd.read_table(<span class="string">'datasets/movielens/users.dat'</span>, sep=<span class="string">'::'</span>,</span><br><span class="line">                      header=<span class="keyword">None</span>, names=unames)</span><br><span class="line"></span><br><span class="line">rnames = [<span class="string">'user_id'</span>, <span class="string">'movie_id'</span>, <span class="string">'rating'</span>, <span class="string">'timestamp'</span>]</span><br><span class="line">ratings = pd.read_table(<span class="string">'datasets/movielens/ratings.dat'</span>, sep=<span class="string">'::'</span>,</span><br><span class="line">                        header=<span class="keyword">None</span>, names=rnames)</span><br><span class="line">mnames = [<span class="string">'movie_id'</span>, <span class="string">'title'</span>, <span class="string">'genres'</span>]</span><br><span class="line">movies = pd.read_table(<span class="string">'datasets/movielens/movies.dat'</span>, sep=<span class="string">'::'</span>,</span><br><span class="line">                       header=<span class="keyword">None</span>, names=mnames)</span><br></pre></td></tr></table></figure></p>
<p>利用Python的切片语法，通过查看每个DataFrame的前几行即可验证数据加载工作是否一切顺利：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">69</span>]: users[:<span class="number">5</span>]</span><br><span class="line">Out[<span class="number">69</span>]: </span><br><span class="line">   user_id gender  age  occupation    zip</span><br><span class="line"><span class="number">0</span>        <span class="number">1</span>      F    <span class="number">1</span>          <span class="number">10</span>  <span class="number">48067</span></span><br><span class="line"><span class="number">1</span>        <span class="number">2</span>      M   <span class="number">56</span>          <span class="number">16</span>  <span class="number">70072</span></span><br><span class="line"><span class="number">2</span>        <span class="number">3</span>      M   <span class="number">25</span>          <span class="number">15</span>  <span class="number">55117</span></span><br><span class="line"><span class="number">3</span>        <span class="number">4</span>      M   <span class="number">45</span>           <span class="number">7</span>  <span class="number">02460</span></span><br><span class="line"><span class="number">4</span>        <span class="number">5</span>      M   <span class="number">25</span>          <span class="number">20</span>  <span class="number">55455</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">70</span>]: ratings[:<span class="number">5</span>]</span><br><span class="line">Out[<span class="number">70</span>]: </span><br><span class="line">   user_id  movie_id  rating  timestamp</span><br><span class="line"><span class="number">0</span>        <span class="number">1</span>      <span class="number">1193</span>       <span class="number">5</span>  <span class="number">978300760</span></span><br><span class="line"><span class="number">1</span>        <span class="number">1</span>       <span class="number">661</span>       <span class="number">3</span>  <span class="number">978302109</span></span><br><span class="line"><span class="number">2</span>        <span class="number">1</span>       <span class="number">914</span>       <span class="number">3</span>  <span class="number">978301968</span></span><br><span class="line"><span class="number">3</span>        <span class="number">1</span>      <span class="number">3408</span>       <span class="number">4</span>  <span class="number">978300275</span></span><br><span class="line"><span class="number">4</span>        <span class="number">1</span>      <span class="number">2355</span>       <span class="number">5</span>  <span class="number">978824291</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">71</span>]: movies[:<span class="number">5</span>]</span><br><span class="line">Out[<span class="number">71</span>]: </span><br><span class="line">   movie_id                               title                        genres</span><br><span class="line"><span class="number">0</span>         <span class="number">1</span>                    Toy Story (<span class="number">1995</span>)   Animation|Children<span class="string">'s|Comedy</span></span><br><span class="line"><span class="string">1         2                      Jumanji (1995)  Adventure|Children'</span>s|Fantasy</span><br><span class="line"><span class="number">2</span>         <span class="number">3</span>             Grumpier Old Men (<span class="number">1995</span>)                Comedy|Romance</span><br><span class="line"><span class="number">3</span>         <span class="number">4</span>            Waiting to Exhale (<span class="number">1995</span>)                  Comedy|Drama</span><br><span class="line"><span class="number">4</span>         <span class="number">5</span>  Father of the Bride Part II (<span class="number">1995</span>)                        Comedy</span><br><span class="line"></span><br><span class="line">In [<span class="number">72</span>]: ratings</span><br><span class="line">Out[<span class="number">72</span>]: </span><br><span class="line">         user_id  movie_id  rating  timestamp</span><br><span class="line"><span class="number">0</span>              <span class="number">1</span>      <span class="number">1193</span>       <span class="number">5</span>  <span class="number">978300760</span></span><br><span class="line"><span class="number">1</span>              <span class="number">1</span>       <span class="number">661</span>       <span class="number">3</span>  <span class="number">978302109</span></span><br><span class="line"><span class="number">2</span>              <span class="number">1</span>       <span class="number">914</span>       <span class="number">3</span>  <span class="number">978301968</span></span><br><span class="line"><span class="number">3</span>              <span class="number">1</span>      <span class="number">3408</span>       <span class="number">4</span>  <span class="number">978300275</span></span><br><span class="line"><span class="number">4</span>              <span class="number">1</span>      <span class="number">2355</span>       <span class="number">5</span>  <span class="number">978824291</span></span><br><span class="line"><span class="meta">... </span>         ...       ...     ...        ...</span><br><span class="line"><span class="number">1000204</span>     <span class="number">6040</span>      <span class="number">1091</span>       <span class="number">1</span>  <span class="number">956716541</span></span><br><span class="line"><span class="number">1000205</span>     <span class="number">6040</span>      <span class="number">1094</span>       <span class="number">5</span>  <span class="number">956704887</span></span><br><span class="line"><span class="number">1000206</span>     <span class="number">6040</span>       <span class="number">562</span>       <span class="number">5</span>  <span class="number">956704746</span></span><br><span class="line"><span class="number">1000207</span>     <span class="number">6040</span>      <span class="number">1096</span>       <span class="number">4</span>  <span class="number">956715648</span></span><br><span class="line"><span class="number">1000208</span>     <span class="number">6040</span>      <span class="number">1097</span>       <span class="number">4</span>  <span class="number">956715569</span></span><br><span class="line">[<span class="number">1000209</span> rows x <span class="number">4</span> columns]</span><br></pre></td></tr></table></figure></p>
<p>注意，其中的年龄和职业是以编码形式给出的，它们的具体含义请参考该数据集的README文件。分析散布在三个表中的数据可不是一件轻松的事情。假设我们想要根据性别和年龄计算某部电影的平均得分，如果将所有数据都合并到一个表中的话问题就简单多了。我们先用pandas的merge函数将ratings跟users合并到一起，然后再将movies也合并进去。pandas会根据列名的重叠情况推断出哪些列是合并（或连接）键：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">73</span>]: data = pd.merge(pd.merge(ratings, users), movies)</span><br><span class="line"></span><br><span class="line">In [<span class="number">74</span>]: data</span><br><span class="line">Out[<span class="number">74</span>]: </span><br><span class="line">         user_id  movie_id  rating  timestamp gender  age  occupation    zip  \</span><br><span class="line"><span class="number">0</span>              <span class="number">1</span>      <span class="number">1193</span>       <span class="number">5</span>  <span class="number">978300760</span>      F    <span class="number">1</span>          <span class="number">10</span>  <span class="number">48067</span>   </span><br><span class="line"><span class="number">1</span>              <span class="number">2</span>      <span class="number">1193</span>       <span class="number">5</span>  <span class="number">978298413</span>      M   <span class="number">56</span>          <span class="number">16</span>  <span class="number">70072</span>   </span><br><span class="line"><span class="number">2</span>             <span class="number">12</span>      <span class="number">1193</span>       <span class="number">4</span>  <span class="number">978220179</span>      M   <span class="number">25</span>          <span class="number">12</span>  <span class="number">32793</span>   </span><br><span class="line"><span class="number">3</span>             <span class="number">15</span>      <span class="number">1193</span>       <span class="number">4</span>  <span class="number">978199279</span>      M   <span class="number">25</span>           <span class="number">7</span>  <span class="number">22903</span>   </span><br><span class="line"><span class="number">4</span>             <span class="number">17</span>      <span class="number">1193</span>       <span class="number">5</span>  <span class="number">978158471</span>      M   <span class="number">50</span>           <span class="number">1</span>  <span class="number">95350</span>   </span><br><span class="line"><span class="meta">... </span>         ...       ...     ...        ...    ...  ...         ...    ...   </span><br><span class="line"><span class="number">1000204</span>     <span class="number">5949</span>      <span class="number">2198</span>       <span class="number">5</span>  <span class="number">958846401</span>      M   <span class="number">18</span>          <span class="number">17</span>  <span class="number">47901</span></span><br><span class="line"><span class="number">1000205</span>     <span class="number">5675</span>      <span class="number">2703</span>       <span class="number">3</span>  <span class="number">976029116</span>      M   <span class="number">35</span>          <span class="number">14</span>  <span class="number">30030</span>   </span><br><span class="line"><span class="number">1000206</span>     <span class="number">5780</span>      <span class="number">2845</span>       <span class="number">1</span>  <span class="number">958153068</span>      M   <span class="number">18</span>          <span class="number">17</span>  <span class="number">92886</span>   </span><br><span class="line"><span class="number">1000207</span>     <span class="number">5851</span>      <span class="number">3607</span>       <span class="number">5</span>  <span class="number">957756608</span>      F   <span class="number">18</span>          <span class="number">20</span>  <span class="number">55410</span>   </span><br><span class="line"><span class="number">1000208</span>     <span class="number">5938</span>      <span class="number">2909</span>       <span class="number">4</span>  <span class="number">957273353</span>      M   <span class="number">25</span>           <span class="number">1</span>  <span class="number">35401</span>   </span><br><span class="line">                                               title                genres  </span><br><span class="line"><span class="number">0</span>             One Flew Over the Cuckoo<span class="string">'s Nest (1975)                 Drama  </span></span><br><span class="line"><span class="string">1             One Flew Over the Cuckoo'</span>s Nest (<span class="number">1975</span>)                 Drama  </span><br><span class="line"><span class="number">2</span>             One Flew Over the Cuckoo<span class="string">'s Nest (1975)                 Drama  </span></span><br><span class="line"><span class="string">3             One Flew Over the Cuckoo'</span>s Nest (<span class="number">1975</span>)                 Drama  </span><br><span class="line"><span class="number">4</span>             One Flew Over the Cuckoo<span class="string">'s Nest (1975)                 Drama  </span></span><br><span class="line"><span class="string">...                                              ...                   ...  </span></span><br><span class="line"><span class="string">1000204                           Modulations (1998)           Documentary  </span></span><br><span class="line"><span class="string">1000205                        Broken Vessels (1998)                 Drama  </span></span><br><span class="line"><span class="string">1000206                            White Boys (1999)                 Drama  </span></span><br><span class="line"><span class="string">1000207                     One Little Indian (1973)  Comedy|Drama|Western  </span></span><br><span class="line"><span class="string">1000208  Five Wives, Three Secretaries and Me (1998)           Documentary  </span></span><br><span class="line"><span class="string">[1000209 rows x 10 columns]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">In [75]: data.iloc[0]</span></span><br><span class="line"><span class="string">Out[75]: </span></span><br><span class="line"><span class="string">user_id                                            1</span></span><br><span class="line"><span class="string">movie_id                                        1193</span></span><br><span class="line"><span class="string">rating                                             5</span></span><br><span class="line"><span class="string">timestamp                                  978300760</span></span><br><span class="line"><span class="string">gender                                             F</span></span><br><span class="line"><span class="string">age                                                1</span></span><br><span class="line"><span class="string">occupation                                        10</span></span><br><span class="line"><span class="string">zip                                            48067</span></span><br><span class="line"><span class="string">title         One Flew Over the Cuckoo'</span>s Nest (<span class="number">1975</span>)</span><br><span class="line">genres                                         Drama</span><br><span class="line">Name: <span class="number">0</span>, dtype: object</span><br></pre></td></tr></table></figure></p>
<p>为了按性别计算每部电影的平均得分，我们可以使用pivot_table方法：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">76</span>]: mean_ratings = data.pivot_table(<span class="string">'rating'</span>, index=<span class="string">'title'</span>,</span><br><span class="line">   ....:                                 columns=<span class="string">'gender'</span>, aggfunc=<span class="string">'mean'</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">77</span>]: mean_ratings[:<span class="number">5</span>]</span><br><span class="line">Out[<span class="number">77</span>]: </span><br><span class="line">gender                                F         M</span><br><span class="line">title                                            </span><br><span class="line">$<span class="number">1</span>,<span class="number">000</span>,<span class="number">000</span> Duck (<span class="number">1971</span>)         <span class="number">3.375000</span>  <span class="number">2.761905</span></span><br><span class="line"><span class="string">'Night Mother (1986)           3.388889  3.352941</span></span><br><span class="line"><span class="string">'</span>Til There Was You (<span class="number">1997</span>)      <span class="number">2.675676</span>  <span class="number">2.733333</span></span><br><span class="line"><span class="string">'burbs, The (1989)             2.793478  2.962085</span></span><br><span class="line"><span class="string">...And Justice for All (1979)  3.828571  3.689024</span></span><br></pre></td></tr></table></figure></p>
<p>该操作产生了另一个DataFrame，其内容为电影平均得分，行标为电影名称（索引），列标为性别。现在，我打算过滤掉评分数据不够250条的电影（随便选的一个数字）。为了达到这个目的，我先对title进行分组，然后利用size()得到一个含有各电影分组大小的Series对象：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">78</span>]: ratings_by_title = data.groupby(<span class="string">'title'</span>).size()</span><br><span class="line"></span><br><span class="line">In [<span class="number">79</span>]: ratings_by_title[:<span class="number">10</span>]</span><br><span class="line">Out[<span class="number">79</span>]: </span><br><span class="line">title</span><br><span class="line">$<span class="number">1</span>,<span class="number">000</span>,<span class="number">000</span> Duck (<span class="number">1971</span>)                <span class="number">37</span></span><br><span class="line"><span class="string">'Night Mother (1986)                  70</span></span><br><span class="line"><span class="string">'</span>Til There Was You (<span class="number">1997</span>)             <span class="number">52</span></span><br><span class="line"><span class="string">'burbs, The (1989)                   303</span></span><br><span class="line"><span class="string">...And Justice for All (1979)        199</span></span><br><span class="line"><span class="string">1-900 (1994)                           2</span></span><br><span class="line"><span class="string">10 Things I Hate About You (1999)    700</span></span><br><span class="line"><span class="string">101 Dalmatians (1961)                565</span></span><br><span class="line"><span class="string">101 Dalmatians (1996)                364</span></span><br><span class="line"><span class="string">12 Angry Men (1957)                  616</span></span><br><span class="line"><span class="string">dtype: int64</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">In [80]: active_titles = ratings_by_title.index[ratings_by_title &gt;= 250]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">In [81]: active_titles</span></span><br><span class="line"><span class="string">Out[81]: </span></span><br><span class="line"><span class="string">Index(['</span><span class="string">'burbs, The (1989)'</span>, <span class="string">'10 Things I Hate About You (1999)'</span>,</span><br><span class="line">       <span class="string">'101 Dalmatians (1961)'</span>, <span class="string">'101 Dalmatians (1996)'</span>, <span class="string">'12 Angry Men (1957)'</span>,</span><br><span class="line">       <span class="string">'13th Warrior, The (1999)'</span>, <span class="string">'2 Days in the Valley (1996)'</span>,</span><br><span class="line">       <span class="string">'20,000 Leagues Under the Sea (1954)'</span>, <span class="string">'2001: A Space Odyssey (1968)'</span>,</span><br><span class="line">       <span class="string">'2010 (1984)'</span>,</span><br><span class="line">       ...</span><br><span class="line"><span class="string">'X-Men (2000)'</span>, <span class="string">'Year of Living Dangerously (1982)'</span>,</span><br><span class="line">       <span class="string">'Yellow Submarine (1968)'</span>, <span class="string">'You'</span>ve Got Mail (<span class="number">1998</span>)<span class="string">',</span></span><br><span class="line"><span class="string">       '</span>Young Frankenstein (<span class="number">1974</span>)<span class="string">', '</span>Young Guns (<span class="number">1988</span>)<span class="string">',</span></span><br><span class="line"><span class="string">       '</span>Young Guns II (<span class="number">1990</span>)<span class="string">', '</span>Young Sherlock Holmes (<span class="number">1985</span>)<span class="string">',</span></span><br><span class="line"><span class="string">       '</span>Zero Effect (<span class="number">1998</span>)<span class="string">', '</span>eXistenZ (<span class="number">1999</span>)<span class="string">'],</span></span><br><span class="line"><span class="string">      dtype='</span>object<span class="string">', name='</span>title<span class="string">', length=1216)</span></span><br></pre></td></tr></table></figure></p>
<p>标题索引中含有评分数据大于250条的电影名称，然后我们就可以据此从前面的mean_ratings中选取所需的行了：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Select rows on the index</span></span><br><span class="line">In [<span class="number">82</span>]: mean_ratings = mean_ratings.loc[active_titles]</span><br><span class="line"></span><br><span class="line">In [<span class="number">83</span>]: mean_ratings</span><br><span class="line">Out[<span class="number">83</span>]: </span><br><span class="line">gender                                    F         M</span><br><span class="line">title                                                </span><br><span class="line"><span class="string">'burbs, The (1989)                 2.793478  2.962085</span></span><br><span class="line"><span class="string">10 Things I Hate About You (1999)  3.646552  3.311966</span></span><br><span class="line"><span class="string">101 Dalmatians (1961)              3.791444  3.500000</span></span><br><span class="line"><span class="string">101 Dalmatians (1996)              3.240000  2.911215</span></span><br><span class="line"><span class="string">12 Angry Men (1957)                4.184397  4.328421</span></span><br><span class="line"><span class="string">...                                     ...       ...</span></span><br><span class="line"><span class="string">Young Guns (1988)                  3.371795  3.425620</span></span><br><span class="line"><span class="string">Young Guns II (1990)               2.934783  2.904025</span></span><br><span class="line"><span class="string">Young Sherlock Holmes (1985)       3.514706  3.363344</span></span><br><span class="line"><span class="string">Zero Effect (1998)                 3.864407  3.723140</span></span><br><span class="line"><span class="string">eXistenZ (1999)                    3.098592  3.289086</span></span><br><span class="line"><span class="string">[1216 rows x 2 columns]</span></span><br></pre></td></tr></table></figure></p>
<p>为了了解女性观众最喜欢的电影，我们可以对F列降序排列：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">85</span>]: top_female_ratings = mean_ratings.sort_values(by=<span class="string">'F'</span>, ascending=<span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">86</span>]: top_female_ratings[:<span class="number">10</span>]</span><br><span class="line">Out[<span class="number">86</span>]: </span><br><span class="line">gender                                                     F         M</span><br><span class="line">title                                                                 </span><br><span class="line">Close Shave, A (<span class="number">1995</span>)                               <span class="number">4.644444</span>  <span class="number">4.473795</span></span><br><span class="line">Wrong Trousers, The (<span class="number">1993</span>)                          <span class="number">4.588235</span>  <span class="number">4.478261</span></span><br><span class="line">Sunset Blvd. (a.k.a. Sunset Boulevard) (<span class="number">1950</span>)       <span class="number">4.572650</span>  <span class="number">4.464589</span></span><br><span class="line">Wallace &amp; Gromit: The Best of Aardman Animation...  <span class="number">4.563107</span>  <span class="number">4.385075</span></span><br><span class="line">Schindle<span class="string">r's List (1993)                             4.562602  4.491415</span></span><br><span class="line"><span class="string">Shawshank Redemption, The (1994)                    4.539075  4.560625</span></span><br><span class="line"><span class="string">Grand Day Out, A (1992)                             4.537879  4.293255</span></span><br><span class="line"><span class="string">To Kill a Mockingbird (1962)                        4.536667  4.372611</span></span><br><span class="line"><span class="string">Creature Comforts (1990)                            4.513889  4.272277</span></span><br><span class="line"><span class="string">Usual Suspects, The (1995)                          4.513317  4.518248</span></span><br></pre></td></tr></table></figure></p>
<h2 id="计算评分分歧"><a href="#计算评分分歧" class="headerlink" title="计算评分分歧"></a>计算评分分歧</h2><p>假设我们想要找出男性和女性观众分歧最大的电影。一个办法是给mean_ratings加上一个用于存放平均得分之差的列，并对其进行排序：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">87</span>]: mean_ratings[<span class="string">'diff'</span>] = mean_ratings[<span class="string">'M'</span>] - mean_ratings[<span class="string">'F'</span>]</span><br></pre></td></tr></table></figure></p>
<p>按”diff”排序即可得到分歧最大且女性观众更喜欢的电影：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">88</span>]: sorted_by_diff = mean_ratings.sort_values(by=<span class="string">'diff'</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">89</span>]: sorted_by_diff[:<span class="number">10</span>]</span><br><span class="line">Out[<span class="number">89</span>]: </span><br><span class="line">gender                                        F         M      diff</span><br><span class="line">title                                                              </span><br><span class="line">Dirty Dancing (<span class="number">1987</span>)                   <span class="number">3.790378</span>  <span class="number">2.959596</span> <span class="number">-0.830782</span></span><br><span class="line">Jumpin<span class="string">' Jack Flash (1986)              3.254717  2.578358 -0.676359</span></span><br><span class="line"><span class="string">Grease (1978)                          3.975265  3.367041 -0.608224</span></span><br><span class="line"><span class="string">Little Women (1994)                    3.870588  3.321739 -0.548849</span></span><br><span class="line"><span class="string">Steel Magnolias (1989)                 3.901734  3.365957 -0.535777</span></span><br><span class="line"><span class="string">Anastasia (1997)                       3.800000  3.281609 -0.518391</span></span><br><span class="line"><span class="string">Rocky Horror Picture Show, The (1975)  3.673016  3.160131 -0.512885</span></span><br><span class="line"><span class="string">Color Purple, The (1985)               4.158192  3.659341 -0.498851</span></span><br><span class="line"><span class="string">Age of Innocence, The (1993)           3.827068  3.339506 -0.487561</span></span><br><span class="line"><span class="string">Free Willy (1993)                      2.921348  2.438776 -0.482573</span></span><br></pre></td></tr></table></figure></p>
<p>对排序结果反序并取出前10行，得到的则是男性观众更喜欢的电影：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Reverse order of rows, take first 10 rows</span></span><br><span class="line">In [<span class="number">90</span>]: sorted_by_diff[::<span class="number">-1</span>][:<span class="number">10</span>]</span><br><span class="line">Out[<span class="number">90</span>]: </span><br><span class="line">gender                                         F         M      diff</span><br><span class="line">title                                                               </span><br><span class="line">Good, The Bad <span class="keyword">and</span> The Ugly, The (<span class="number">1966</span>)  <span class="number">3.494949</span>  <span class="number">4.221300</span>  <span class="number">0.726351</span></span><br><span class="line">Kentucky Fried Movie, The (<span class="number">1977</span>)        <span class="number">2.878788</span>  <span class="number">3.555147</span>  <span class="number">0.676359</span></span><br><span class="line">Dumb &amp; Dumber (<span class="number">1994</span>)                    <span class="number">2.697987</span>  <span class="number">3.336595</span>  <span class="number">0.638608</span></span><br><span class="line">Longest Day, The (<span class="number">1962</span>)                 <span class="number">3.411765</span>  <span class="number">4.031447</span>  <span class="number">0.619682</span></span><br><span class="line">Cable Guy, The (<span class="number">1996</span>)                   <span class="number">2.250000</span>  <span class="number">2.863787</span>  <span class="number">0.613787</span></span><br><span class="line">Evil Dead II (Dead By Dawn) (<span class="number">1987</span>)      <span class="number">3.297297</span>  <span class="number">3.909283</span>  <span class="number">0.611985</span></span><br><span class="line">Hidden, The (<span class="number">1987</span>)                      <span class="number">3.137931</span>  <span class="number">3.745098</span>  <span class="number">0.607167</span></span><br><span class="line">Rocky III (<span class="number">1982</span>)                        <span class="number">2.361702</span>  <span class="number">2.943503</span>  <span class="number">0.581801</span></span><br><span class="line">Caddyshack (<span class="number">1980</span>)                       <span class="number">3.396135</span>  <span class="number">3.969737</span>  <span class="number">0.573602</span></span><br><span class="line">For a Few Dollars More (<span class="number">1965</span>)           <span class="number">3.409091</span>  <span class="number">3.953795</span>  <span class="number">0.544704</span></span><br></pre></td></tr></table></figure></p>
<p>如果只是想要找出分歧最大的电影（不考虑性别因素），则可以计算得分数据的方差或标准差：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Standard deviation of rating grouped by title</span></span><br><span class="line">In [<span class="number">91</span>]: rating_std_by_title = data.groupby(<span class="string">'title'</span>)[<span class="string">'rating'</span>].std()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Filter down to active_titles</span></span><br><span class="line">In [<span class="number">92</span>]: rating_std_by_title = rating_std_by_title.loc[active_titles]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Order Series by value in descending order</span></span><br><span class="line">In [<span class="number">93</span>]: rating_std_by_title.sort_values(ascending=<span class="keyword">False</span>)[:<span class="number">10</span>]</span><br><span class="line">Out[<span class="number">93</span>]: </span><br><span class="line">title</span><br><span class="line">Dumb &amp; Dumber (<span class="number">1994</span>)                     <span class="number">1.321333</span></span><br><span class="line">Blair Witch Project, The (<span class="number">1999</span>)          <span class="number">1.316368</span></span><br><span class="line">Natural Born Killers (<span class="number">1994</span>)              <span class="number">1.307198</span></span><br><span class="line">Tank Girl (<span class="number">1995</span>)                         <span class="number">1.277695</span></span><br><span class="line">Rocky Horror Picture Show, The (<span class="number">1975</span>)    <span class="number">1.260177</span></span><br><span class="line">Eyes Wide Shut (<span class="number">1999</span>)                    <span class="number">1.259624</span></span><br><span class="line">Evita (<span class="number">1996</span>)                             <span class="number">1.253631</span></span><br><span class="line">Billy Madison (<span class="number">1995</span>)                     <span class="number">1.249970</span></span><br><span class="line">Fear <span class="keyword">and</span> Loathing <span class="keyword">in</span> Las Vegas (<span class="number">1998</span>)    <span class="number">1.246408</span></span><br><span class="line">Bicentennial Man (<span class="number">1999</span>)                  <span class="number">1.245533</span></span><br><span class="line">Name: rating, dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>可能你已经注意到了，电影分类是以竖线（|）分隔的字符串形式给出的。如果想对电影分类进行分析的话，就需要先将其转换成更有用的形式才行。</p>
<h1 id="14-3-1880-2010年间全美婴儿姓名"><a href="#14-3-1880-2010年间全美婴儿姓名" class="headerlink" title="14.3 1880-2010年间全美婴儿姓名"></a>14.3 1880-2010年间全美婴儿姓名</h1><p>美国社会保障总署（SSA）提供了一份从1880年到现在的婴儿名字频率数据。Hadley Wickham（许多流行R包的作者）经常用这份数据来演示R的数据处理功能。</p>
<p>我们要做一些数据规整才能加载这个数据集，这么做就会产生一个如下的DataFrame：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">4</span>]: names.head(<span class="number">10</span>)</span><br><span class="line">Out[<span class="number">4</span>]:</span><br><span class="line">        name sex  births  year</span><br><span class="line"><span class="number">0</span>       Mary   F    <span class="number">7065</span>  <span class="number">1880</span></span><br><span class="line"><span class="number">1</span>       Anna   F    <span class="number">2604</span>  <span class="number">1880</span></span><br><span class="line"><span class="number">2</span>       Emma   F    <span class="number">2003</span>  <span class="number">1880</span></span><br><span class="line"><span class="number">3</span>  Elizabeth   F    <span class="number">1939</span>  <span class="number">1880</span></span><br><span class="line"><span class="number">4</span>     Minnie   F    <span class="number">1746</span>  <span class="number">1880</span></span><br><span class="line"><span class="number">5</span>   Margaret   F    <span class="number">1578</span>  <span class="number">1880</span></span><br><span class="line"><span class="number">6</span>        Ida   F    <span class="number">1472</span>  <span class="number">1880</span></span><br><span class="line"><span class="number">7</span>      Alice   F    <span class="number">1414</span>  <span class="number">1880</span></span><br><span class="line"><span class="number">8</span>     Bertha   F    <span class="number">1320</span>  <span class="number">1880</span></span><br><span class="line"><span class="number">9</span>      Sarah   F    <span class="number">1288</span>  <span class="number">1880</span></span><br></pre></td></tr></table></figure></p>
<p>你可以用这个数据集做很多事，例如：</p>
<ul>
<li>计算指定名字（可以是你自己的，也可以是别人的）的年度比例。</li>
<li>计算某个名字的相对排名。</li>
<li>计算各年度最流行的名字，以及增长或减少最快的名字。</li>
<li>分析名字趋势：元音、辅音、长度、总体多样性、拼写变化、首尾字母等。</li>
<li>分析外源性趋势：圣经中的名字、名人、人口结构变化等。</li>
</ul>
<p>利用前面介绍过的那些工具，这些分析工作都能很轻松地完成，我会讲解其中的一些。</p>
<p>到编写本书时为止，美国社会保障总署将该数据库按年度制成了多个数据文件，其中给出了每个性别/名字组合的出生总数。这些文件的原始档案可以在这里获取：<a href="http://www.ssa.gov/oact/babynames/limits.html" target="_blank" rel="noopener">http://www.ssa.gov/oact/babynames/limits.html</a>。</p>
<p>如果你在阅读本书的时候这个页面已经不见了，也可以用搜索引擎找找。</p>
<p>下载”National data”文件names.zip，解压后的目录中含有一组文件（如yob1880.txt）。我用UNIX的head命令查看了其中一个文件的前10行（在Windows上，你可以用more命令，或直接在文本编辑器中打开）：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">In [94]: !head -n 10 datasets/babynames/yob1880.txt</span><br><span class="line">Mary,F,7065</span><br><span class="line">Anna,F,2604</span><br><span class="line">Emma,F,2003</span><br><span class="line">Elizabeth,F,1939</span><br><span class="line">Minnie,F,1746</span><br><span class="line">Margaret,F,1578</span><br><span class="line">Ida,F,1472</span><br><span class="line">Alice,F,1414</span><br><span class="line">Bertha,F,1320</span><br><span class="line">Sarah,F,1288</span><br></pre></td></tr></table></figure></p>
<p>由于这是一个非常标准的以逗号隔开的格式，所以可以用pandas.read_csv将其加载到DataFrame中：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">95</span>]: <span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">In [<span class="number">96</span>]: names1880 =</span><br><span class="line">pd.read_csv(<span class="string">'datasets/babynames/yob1880.txt'</span>,</span><br><span class="line">   ....:                         names=[<span class="string">'name'</span>, <span class="string">'sex'</span>, <span class="string">'births'</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">97</span>]: names1880</span><br><span class="line">Out[<span class="number">97</span>]: </span><br><span class="line">           name sex  births</span><br><span class="line"><span class="number">0</span>          Mary   F    <span class="number">7065</span></span><br><span class="line"><span class="number">1</span>          Anna   F    <span class="number">2604</span></span><br><span class="line"><span class="number">2</span>          Emma   F    <span class="number">2003</span></span><br><span class="line"><span class="number">3</span>     Elizabeth   F    <span class="number">1939</span></span><br><span class="line"><span class="number">4</span>        Minnie   F    <span class="number">1746</span></span><br><span class="line"><span class="meta">... </span>        ...  ..     ...</span><br><span class="line"><span class="number">1995</span>     Woodie   M       <span class="number">5</span></span><br><span class="line"><span class="number">1996</span>     Worthy   M       <span class="number">5</span></span><br><span class="line"><span class="number">1997</span>     Wright   M       <span class="number">5</span></span><br><span class="line"><span class="number">1998</span>       York   M       <span class="number">5</span></span><br><span class="line"><span class="number">1999</span>  Zachariah   M       <span class="number">5</span></span><br><span class="line">[<span class="number">2000</span> rows x <span class="number">3</span> columns]</span><br></pre></td></tr></table></figure></p>
<p>这些文件中仅含有当年出现超过5次的名字。为了简单起见，我们可以用births列的sex分组小计表示该年度的births总计：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">98</span>]: names1880.groupby(<span class="string">'sex'</span>).births.sum()</span><br><span class="line">Out[<span class="number">98</span>]: </span><br><span class="line">sex</span><br><span class="line">F     <span class="number">90993</span></span><br><span class="line">M    <span class="number">110493</span></span><br><span class="line">Name: births, dtype: int64</span><br></pre></td></tr></table></figure></p>
<p>由于该数据集按年度被分隔成了多个文件，所以第一件事情就是要将所有数据都组装到一个DataFrame里面，并加上一个year字段。使用pandas.concat即可达到这个目的：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">years = range(<span class="number">1880</span>, <span class="number">2011</span>)</span><br><span class="line"></span><br><span class="line">pieces = []</span><br><span class="line">columns = [<span class="string">'name'</span>, <span class="string">'sex'</span>, <span class="string">'births'</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> year <span class="keyword">in</span> years:</span><br><span class="line">    path = <span class="string">'datasets/babynames/yob%d.txt'</span> % year</span><br><span class="line">    frame = pd.read_csv(path, names=columns)</span><br><span class="line"></span><br><span class="line">    frame[<span class="string">'year'</span>] = year</span><br><span class="line">    pieces.append(frame)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Concatenate everything into a single DataFrame</span></span><br><span class="line">names = pd.concat(pieces, ignore_index=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure></p>
<p>这里需要注意几件事情。第一，concat默认是按行将多个DataFrame组合到一起的；第二，必须指定ignore_index=True，因为我们不希望保留read_csv所返回的原始行号。现在我们得到了一个非常大的DataFrame，它含有全部的名字数据：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">100</span>]: names</span><br><span class="line">Out[<span class="number">100</span>]: </span><br><span class="line">              name sex  births  year</span><br><span class="line"><span class="number">0</span>             Mary   F    <span class="number">7065</span>  <span class="number">1880</span></span><br><span class="line"><span class="number">1</span>             Anna   F    <span class="number">2604</span>  <span class="number">1880</span></span><br><span class="line"><span class="number">2</span>             Emma   F    <span class="number">2003</span>  <span class="number">1880</span></span><br><span class="line"><span class="number">3</span>        Elizabeth   F    <span class="number">1939</span>  <span class="number">1880</span></span><br><span class="line"><span class="number">4</span>           Minnie   F    <span class="number">1746</span>  <span class="number">1880</span></span><br><span class="line"><span class="meta">... </span>           ...  ..     ...   ...</span><br><span class="line"><span class="number">1690779</span>    Zymaire   M       <span class="number">5</span>  <span class="number">2010</span></span><br><span class="line"><span class="number">1690780</span>     Zyonne   M       <span class="number">5</span>  <span class="number">2010</span></span><br><span class="line"><span class="number">1690781</span>  Zyquarius   M       <span class="number">5</span>  <span class="number">2010</span></span><br><span class="line"><span class="number">1690782</span>      Zyran   M       <span class="number">5</span>  <span class="number">2010</span></span><br><span class="line"><span class="number">1690783</span>      Zzyzx   M       <span class="number">5</span>  <span class="number">2010</span></span><br><span class="line">[<span class="number">1690784</span> rows x <span class="number">4</span> columns]</span><br></pre></td></tr></table></figure></p>
<p>有了这些数据之后，我们就可以利用groupby或pivot_table在year和sex级别上对其进行聚合了，如图14-4所示：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">101</span>]: total_births = names.pivot_table(<span class="string">'births'</span>, index=<span class="string">'year'</span>,</span><br><span class="line">   .....:                                  columns=<span class="string">'sex'</span>, aggfunc=sum)</span><br><span class="line"></span><br><span class="line">In [<span class="number">102</span>]: total_births.tail()</span><br><span class="line">Out[<span class="number">102</span>]: </span><br><span class="line">sex         F        M</span><br><span class="line">year                  </span><br><span class="line"><span class="number">2006</span>  <span class="number">1896468</span>  <span class="number">2050234</span></span><br><span class="line"><span class="number">2007</span>  <span class="number">1916888</span>  <span class="number">2069242</span></span><br><span class="line"><span class="number">2008</span>  <span class="number">1883645</span>  <span class="number">2032310</span></span><br><span class="line"><span class="number">2009</span>  <span class="number">1827643</span>  <span class="number">1973359</span></span><br><span class="line"><span class="number">2010</span>  <span class="number">1759010</span>  <span class="number">1898382</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">103</span>]: total_births.plot(title=<span class="string">'Total births by sex and year'</span>)</span><br></pre></td></tr></table></figure></p>
<p><img src="http://upload-images.jianshu.io/upload_images/7178691-7643b150d88aae11.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图14-4 按性别和年度统计的总出生数"></p>
<p>下面我们来插入一个prop列，用于存放指定名字的婴儿数相对于总出生数的比例。prop值为0.02表示每100名婴儿中有2名取了当前这个名字。因此，我们先按year和sex分组，然后再将新列加到各个分组上：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_prop</span><span class="params">(group)</span>:</span></span><br><span class="line">    group[<span class="string">'prop'</span>] = group.births / group.births.sum()</span><br><span class="line">    <span class="keyword">return</span> group</span><br><span class="line">names = names.groupby([<span class="string">'year'</span>, <span class="string">'sex'</span>]).apply(add_prop)</span><br></pre></td></tr></table></figure></p>
<p>现在，完整的数据集就有了下面这些列：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">105</span>]: names</span><br><span class="line">Out[<span class="number">105</span>]: </span><br><span class="line">              name sex  births  year      prop</span><br><span class="line"><span class="number">0</span>             Mary   F    <span class="number">7065</span>  <span class="number">1880</span>  <span class="number">0.077643</span></span><br><span class="line"><span class="number">1</span>             Anna   F    <span class="number">2604</span>  <span class="number">1880</span>  <span class="number">0.028618</span></span><br><span class="line"><span class="number">2</span>             Emma   F    <span class="number">2003</span>  <span class="number">1880</span>  <span class="number">0.022013</span></span><br><span class="line"><span class="number">3</span>        Elizabeth   F    <span class="number">1939</span>  <span class="number">1880</span>  <span class="number">0.021309</span></span><br><span class="line"><span class="number">4</span>           Minnie   F    <span class="number">1746</span>  <span class="number">1880</span>  <span class="number">0.019188</span></span><br><span class="line"><span class="meta">... </span>           ...  ..     ...   ...       ...</span><br><span class="line"><span class="number">1690779</span>    Zymaire   M       <span class="number">5</span>  <span class="number">2010</span>  <span class="number">0.000003</span></span><br><span class="line"><span class="number">1690780</span>     Zyonne   M       <span class="number">5</span>  <span class="number">2010</span>  <span class="number">0.000003</span></span><br><span class="line"><span class="number">1690781</span>  Zyquarius   M       <span class="number">5</span>  <span class="number">2010</span>  <span class="number">0.000003</span></span><br><span class="line"><span class="number">1690782</span>      Zyran   M       <span class="number">5</span>  <span class="number">2010</span>  <span class="number">0.000003</span></span><br><span class="line"><span class="number">1690783</span>      Zzyzx   M       <span class="number">5</span>  <span class="number">2010</span>  <span class="number">0.000003</span></span><br><span class="line">[<span class="number">1690784</span> rows x <span class="number">5</span> columns]</span><br></pre></td></tr></table></figure></p>
<p>在执行这样的分组处理时，一般都应该做一些有效性检查，比如验证所有分组的prop的总和是否为1：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">106</span>]: names.groupby([<span class="string">'year'</span>, <span class="string">'sex'</span>]).prop.sum()</span><br><span class="line">Out[<span class="number">106</span>]: </span><br><span class="line">year  sex</span><br><span class="line"><span class="number">1880</span>  F      <span class="number">1.0</span></span><br><span class="line">      M      <span class="number">1.0</span></span><br><span class="line"><span class="number">1881</span>  F      <span class="number">1.0</span></span><br><span class="line">      M      <span class="number">1.0</span></span><br><span class="line"><span class="number">1882</span>  F      <span class="number">1.0</span></span><br><span class="line">            ... </span><br><span class="line"><span class="number">2008</span>  M      <span class="number">1.0</span></span><br><span class="line"><span class="number">2009</span>  F      <span class="number">1.0</span></span><br><span class="line">      M      <span class="number">1.0</span></span><br><span class="line"><span class="number">2010</span>  F      <span class="number">1.0</span></span><br><span class="line">      M      <span class="number">1.0</span></span><br><span class="line">Name: prop, Length: <span class="number">262</span>, dtype: float64</span><br></pre></td></tr></table></figure></p>
<p>工作完成。为了便于实现更进一步的分析，我需要取出该数据的一个子集：每对sex/year组合的前1000个名字。这又是一个分组操作：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_top1000</span><span class="params">(group)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> group.sort_values(by=<span class="string">'births'</span>, ascending=<span class="keyword">False</span>)[:<span class="number">1000</span>]</span><br><span class="line">grouped = names.groupby([<span class="string">'year'</span>, <span class="string">'sex'</span>])</span><br><span class="line">top1000 = grouped.apply(get_top1000)</span><br><span class="line"><span class="comment"># Drop the group index, not needed</span></span><br><span class="line">top1000.reset_index(inplace=<span class="keyword">True</span>, drop=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure></p>
<p>如果你喜欢DIY的话，也可以这样：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pieces = []</span><br><span class="line"><span class="keyword">for</span> year, group <span class="keyword">in</span> names.groupby([<span class="string">'year'</span>, <span class="string">'sex'</span>]):</span><br><span class="line">    pieces.append(group.sort_values(by=<span class="string">'births'</span>, ascending=<span class="keyword">False</span>)[:<span class="number">1000</span>])</span><br><span class="line">top1000 = pd.concat(pieces, ignore_index=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure></p>
<p>现在的结果数据集就小多了：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">108</span>]: top1000</span><br><span class="line">Out[<span class="number">108</span>]: </span><br><span class="line">             name sex  births  year      prop</span><br><span class="line"><span class="number">0</span>            Mary   F    <span class="number">7065</span>  <span class="number">1880</span>  <span class="number">0.077643</span></span><br><span class="line"><span class="number">1</span>            Anna   F    <span class="number">2604</span>  <span class="number">1880</span>  <span class="number">0.028618</span></span><br><span class="line"><span class="number">2</span>            Emma   F    <span class="number">2003</span>  <span class="number">1880</span>  <span class="number">0.022013</span></span><br><span class="line"><span class="number">3</span>       Elizabeth   F    <span class="number">1939</span>  <span class="number">1880</span>  <span class="number">0.021309</span></span><br><span class="line"><span class="number">4</span>          Minnie   F    <span class="number">1746</span>  <span class="number">1880</span>  <span class="number">0.019188</span></span><br><span class="line"><span class="meta">... </span>          ...  ..     ...   ...       ...</span><br><span class="line"><span class="number">261872</span>     Camilo   M     <span class="number">194</span>  <span class="number">2010</span>  <span class="number">0.000102</span></span><br><span class="line"><span class="number">261873</span>     Destin   M     <span class="number">194</span>  <span class="number">2010</span>  <span class="number">0.000102</span></span><br><span class="line"><span class="number">261874</span>     Jaquan   M     <span class="number">194</span>  <span class="number">2010</span>  <span class="number">0.000102</span></span><br><span class="line"><span class="number">261875</span>     Jaydan   M     <span class="number">194</span>  <span class="number">2010</span>  <span class="number">0.000102</span></span><br><span class="line"><span class="number">261876</span>     Maxton   M     <span class="number">193</span>  <span class="number">2010</span>  <span class="number">0.000102</span></span><br><span class="line">[<span class="number">261877</span> rows x <span class="number">5</span> columns]</span><br></pre></td></tr></table></figure></p>
<p>接下来的数据分析工作就针对这个top1000数据集了。</p>
<h2 id="分析命名趋势"><a href="#分析命名趋势" class="headerlink" title="分析命名趋势"></a>分析命名趋势</h2><p>有了完整的数据集和刚才生成的top1000数据集，我们就可以开始分析各种命名趋势了。首先将前1000个名字分为男女两个部分：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">109</span>]: boys = top1000[top1000.sex == <span class="string">'M'</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">110</span>]: girls = top1000[top1000.sex == <span class="string">'F'</span>]</span><br></pre></td></tr></table></figure></p>
<p>这是两个简单的时间序列，只需稍作整理即可绘制出相应的图表（比如每年叫做John和Mary的婴儿数）。我们先生成一张按year和name统计的总出生数透视表：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">111</span>]: total_births = top1000.pivot_table(<span class="string">'births'</span>, index=<span class="string">'year'</span>,</span><br><span class="line">   .....:                                    columns=<span class="string">'name'</span>,</span><br><span class="line">   .....:                                    aggfunc=sum)</span><br></pre></td></tr></table></figure></p>
<p>现在，我们用DataFrame的plot方法绘制几个名字的曲线图（见图14-5）：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">112</span>]: total_births.info()</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">pandas</span>.<span class="title">core</span>.<span class="title">frame</span>.<span class="title">DataFrame</span>'&gt;</span></span><br><span class="line"><span class="class"><span class="title">Int64Index</span>:</span> <span class="number">131</span> entries, <span class="number">1880</span> to <span class="number">2010</span></span><br><span class="line">Columns: <span class="number">6868</span> entries, Aaden to Zuri</span><br><span class="line">dtypes: float64(<span class="number">6868</span>)</span><br><span class="line">memory usage: <span class="number">6.9</span> MB</span><br><span class="line"></span><br><span class="line">In [<span class="number">113</span>]: subset = total_births[[<span class="string">'John'</span>, <span class="string">'Harry'</span>, <span class="string">'Mary'</span>, <span class="string">'Marilyn'</span>]]</span><br><span class="line"></span><br><span class="line">In [<span class="number">114</span>]: subset.plot(subplots=<span class="keyword">True</span>, figsize=(<span class="number">12</span>, <span class="number">10</span>), grid=<span class="keyword">False</span>,</span><br><span class="line">   .....:             title=<span class="string">"Number of births per year"</span>)</span><br></pre></td></tr></table></figure></p>
<p><img src="http://upload-images.jianshu.io/upload_images/7178691-33f0f97656367a53.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图14-5 几个男孩和女孩名字随时间变化的使用数量"></p>
<p>从图中可以看出，这几个名字在美国人民的心目中已经风光不再了。但事实并非如此简单，我们在下一节中就能知道是怎么一回事了。</p>
<h2 id="评估命名多样性的增长"><a href="#评估命名多样性的增长" class="headerlink" title="评估命名多样性的增长"></a>评估命名多样性的增长</h2><p>一种解释是父母愿意给小孩起常见的名字越来越少。这个假设可以从数据中得到验证。一个办法是计算最流行的1000个名字所占的比例，我按year和sex进行聚合并绘图（见图14-6）：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">116</span>]: table = top1000.pivot_table(<span class="string">'prop'</span>, index=<span class="string">'year'</span>,</span><br><span class="line">   .....:                             columns=<span class="string">'sex'</span>, aggfunc=sum)</span><br><span class="line"></span><br><span class="line">In [<span class="number">117</span>]: table.plot(title=<span class="string">'Sum of table1000.prop by year and sex'</span>,</span><br><span class="line">   .....:            yticks=np.linspace(<span class="number">0</span>, <span class="number">1.2</span>, <span class="number">13</span>), xticks=range(<span class="number">1880</span>, <span class="number">2020</span>, <span class="number">10</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure></p>
<p><img src="http://upload-images.jianshu.io/upload_images/7178691-63e1ddc326a033b9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图14-6 分性别统计的前1000个名字在总出生人数中的比例"></p>
<p>从图中可以看出，名字的多样性确实出现了增长（前1000项的比例降低）。另一个办法是计算占总出生人数前50%的不同名字的数量，这个数字不太好计算。我们只考虑2010年男孩的名字：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">118</span>]: df = boys[boys.year == <span class="number">2010</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">119</span>]: df</span><br><span class="line">Out[<span class="number">119</span>]: </span><br><span class="line">           name sex  births  year      prop</span><br><span class="line"><span class="number">260877</span>    Jacob   M   <span class="number">21875</span>  <span class="number">2010</span>  <span class="number">0.011523</span></span><br><span class="line"><span class="number">260878</span>    Ethan   M   <span class="number">17866</span>  <span class="number">2010</span>  <span class="number">0.009411</span></span><br><span class="line"><span class="number">260879</span>  Michael   M   <span class="number">17133</span>  <span class="number">2010</span>  <span class="number">0.009025</span></span><br><span class="line"><span class="number">260880</span>   Jayden   M   <span class="number">17030</span>  <span class="number">2010</span>  <span class="number">0.008971</span></span><br><span class="line"><span class="number">260881</span>  William   M   <span class="number">16870</span>  <span class="number">2010</span>  <span class="number">0.008887</span></span><br><span class="line"><span class="meta">... </span>        ...  ..     ...   ...       ...</span><br><span class="line"><span class="number">261872</span>   Camilo   M     <span class="number">194</span>  <span class="number">2010</span>  <span class="number">0.000102</span></span><br><span class="line"><span class="number">261873</span>   Destin   M     <span class="number">194</span>  <span class="number">2010</span>  <span class="number">0.000102</span></span><br><span class="line"><span class="number">261874</span>   Jaquan   M     <span class="number">194</span>  <span class="number">2010</span>  <span class="number">0.000102</span></span><br><span class="line"><span class="number">261875</span>   Jaydan   M     <span class="number">194</span>  <span class="number">2010</span>  <span class="number">0.000102</span></span><br><span class="line"><span class="number">261876</span>   Maxton   M     <span class="number">193</span>  <span class="number">2010</span>  <span class="number">0.000102</span></span><br><span class="line">[<span class="number">1000</span> rows x <span class="number">5</span> columns]</span><br></pre></td></tr></table></figure></p>
<p>在对prop降序排列之后，我们想知道前面多少个名字的人数加起来才够50%。虽然编写一个for循环确实也能达到目的，但NumPy有一种更聪明的矢量方式。先计算prop的累计和cumsum，然后再通过searchsorted方法找出0.5应该被插入在哪个位置才能保证不破坏顺序：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">120</span>]: prop_cumsum = df.sort_values(by=<span class="string">'prop'</span>, ascending=<span class="keyword">False</span>).prop.cumsum()</span><br><span class="line"></span><br><span class="line">In [<span class="number">121</span>]: prop_cumsum[:<span class="number">10</span>]</span><br><span class="line">Out[<span class="number">121</span>]: </span><br><span class="line"><span class="number">260877</span>    <span class="number">0.011523</span></span><br><span class="line"><span class="number">260878</span>    <span class="number">0.020934</span></span><br><span class="line"><span class="number">260879</span>    <span class="number">0.029959</span></span><br><span class="line"><span class="number">260880</span>    <span class="number">0.038930</span></span><br><span class="line"><span class="number">260881</span>    <span class="number">0.047817</span></span><br><span class="line"><span class="number">260882</span>    <span class="number">0.056579</span></span><br><span class="line"><span class="number">260883</span>    <span class="number">0.065155</span></span><br><span class="line"><span class="number">260884</span>    <span class="number">0.073414</span></span><br><span class="line"><span class="number">260885</span>    <span class="number">0.081528</span></span><br><span class="line"><span class="number">260886</span>    <span class="number">0.089621</span></span><br><span class="line">Name: prop, dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">122</span>]: prop_cumsum.values.searchsorted(<span class="number">0.5</span>)</span><br><span class="line">Out[<span class="number">122</span>]: <span class="number">116</span></span><br></pre></td></tr></table></figure></p>
<p>由于数组索引是从0开始的，因此我们要给这个结果加1，即最终结果为117。拿1900年的数据来做个比较，这个数字要小得多：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">123</span>]: df = boys[boys.year == <span class="number">1900</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">124</span>]: in1900 = df.sort_values(by=<span class="string">'prop'</span>, ascending=<span class="keyword">False</span>).prop.cumsum()</span><br><span class="line"></span><br><span class="line">In [<span class="number">125</span>]: in1900.values.searchsorted(<span class="number">0.5</span>) + <span class="number">1</span></span><br><span class="line">Out[<span class="number">125</span>]: <span class="number">25</span></span><br></pre></td></tr></table></figure></p>
<p>现在就可以对所有year/sex组合执行这个计算了。按这两个字段进行groupby处理，然后用一个函数计算各分组的这个值：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_quantile_count</span><span class="params">(group, q=<span class="number">0.5</span>)</span>:</span></span><br><span class="line">    group = group.sort_values(by=<span class="string">'prop'</span>, ascending=<span class="keyword">False</span>)</span><br><span class="line">    <span class="keyword">return</span> group.prop.cumsum().values.searchsorted(q) + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">diversity = top1000.groupby([<span class="string">'year'</span>, <span class="string">'sex'</span>]).apply(get_quantile_count)</span><br><span class="line">diversity = diversity.unstack(<span class="string">'sex'</span>)</span><br></pre></td></tr></table></figure></p>
<p>现在，diversity这个DataFrame拥有两个时间序列（每个性别各一个，按年度索引）。通过IPython，你可以查看其内容，还可以像之前那样绘制图表（如图14-7所示）：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">128</span>]: diversity.head()</span><br><span class="line">Out[<span class="number">128</span>]: </span><br><span class="line">sex    F   M</span><br><span class="line">year        </span><br><span class="line"><span class="number">1880</span>  <span class="number">38</span>  <span class="number">14</span></span><br><span class="line"><span class="number">1881</span>  <span class="number">38</span>  <span class="number">14</span></span><br><span class="line"><span class="number">1882</span>  <span class="number">38</span>  <span class="number">15</span></span><br><span class="line"><span class="number">1883</span>  <span class="number">39</span>  <span class="number">15</span></span><br><span class="line"><span class="number">1884</span>  <span class="number">39</span>  <span class="number">16</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">129</span>]: diversity.plot(title=<span class="string">"Number of popular names in top 50%"</span>)</span><br></pre></td></tr></table></figure></p>
<p><img src="http://upload-images.jianshu.io/upload_images/7178691-574b53a383cad681.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图14-7 按年度统计的密度表"></p>
<p>从图中可以看出，女孩名字的多样性总是比男孩的高，而且还在变得越来越高。读者们可以自己分析一下具体是什么在驱动这个多样性（比如拼写形式的变化）。</p>
<h2 id="“最后一个字母”的变革"><a href="#“最后一个字母”的变革" class="headerlink" title="“最后一个字母”的变革"></a>“最后一个字母”的变革</h2><p>2007年，一名婴儿姓名研究人员Laura Wattenberg在她自己的网站上指出（<a href="http://www.babynamewizard.com）：近百年来，男孩名字在最后一个字母上的分布发生了显著的变化。为了了解具体的情况，我首先将全部出生数据在年度、性别以及末字母上进行了聚合：" target="_blank" rel="noopener">http://www.babynamewizard.com）：近百年来，男孩名字在最后一个字母上的分布发生了显著的变化。为了了解具体的情况，我首先将全部出生数据在年度、性别以及末字母上进行了聚合：</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># extract last letter from name column</span></span><br><span class="line">get_last_letter = <span class="keyword">lambda</span> x: x[<span class="number">-1</span>]</span><br><span class="line">last_letters = names.name.map(get_last_letter)</span><br><span class="line">last_letters.name = <span class="string">'last_letter'</span></span><br><span class="line"></span><br><span class="line">table = names.pivot_table(<span class="string">'births'</span>, index=last_letters,</span><br><span class="line">                          columns=[<span class="string">'sex'</span>, <span class="string">'year'</span>], aggfunc=sum)</span><br></pre></td></tr></table></figure></p>
<p>然后，我选出具有一定代表性的三年，并输出前面几行：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">131</span>]: subtable = table.reindex(columns=[<span class="number">1910</span>, <span class="number">1960</span>, <span class="number">2010</span>], level=<span class="string">'year'</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">132</span>]: subtable.head()</span><br><span class="line">Out[<span class="number">132</span>]: </span><br><span class="line">sex                 F                            M                    </span><br><span class="line">year             <span class="number">1910</span>      <span class="number">1960</span>      <span class="number">2010</span>     <span class="number">1910</span>      <span class="number">1960</span>      <span class="number">2010</span></span><br><span class="line">last_letter                                                           </span><br><span class="line">a            <span class="number">108376.0</span>  <span class="number">691247.0</span>  <span class="number">670605.0</span>    <span class="number">977.0</span>    <span class="number">5204.0</span>   <span class="number">28438.0</span></span><br><span class="line">b                 NaN     <span class="number">694.0</span>     <span class="number">450.0</span>    <span class="number">411.0</span>    <span class="number">3912.0</span>   <span class="number">38859.0</span></span><br><span class="line">c                 <span class="number">5.0</span>      <span class="number">49.0</span>     <span class="number">946.0</span>    <span class="number">482.0</span>   <span class="number">15476.0</span>   <span class="number">23125.0</span></span><br><span class="line">d              <span class="number">6750.0</span>    <span class="number">3729.0</span>    <span class="number">2607.0</span>  <span class="number">22111.0</span>  <span class="number">262112.0</span>   <span class="number">44398.0</span></span><br><span class="line">e            <span class="number">133569.0</span>  <span class="number">435013.0</span>  <span class="number">313833.0</span>  <span class="number">28655.0</span>  <span class="number">178823.0</span>  <span class="number">129012.0</span></span><br></pre></td></tr></table></figure></p>
<p>接下来我们需要按总出生数对该表进行规范化处理，以便计算出各性别各末字母占总出生人数的比例：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">133</span>]: subtable.sum()</span><br><span class="line">Out[<span class="number">133</span>]: </span><br><span class="line">sex  year</span><br><span class="line">F    <span class="number">1910</span>     <span class="number">396416.0</span></span><br><span class="line">     <span class="number">1960</span>    <span class="number">2022062.0</span></span><br><span class="line">     <span class="number">2010</span>    <span class="number">1759010.0</span></span><br><span class="line">M    <span class="number">1910</span>     <span class="number">194198.0</span></span><br><span class="line">     <span class="number">1960</span>    <span class="number">2132588.0</span></span><br><span class="line"><span class="number">2010</span>    <span class="number">1898382.0</span></span><br><span class="line">dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">134</span>]: letter_prop = subtable / subtable.sum()</span><br><span class="line"></span><br><span class="line">In [<span class="number">135</span>]: letter_prop</span><br><span class="line">Out[<span class="number">135</span>]: </span><br><span class="line">sex                 F                             M                    </span><br><span class="line">year             <span class="number">1910</span>      <span class="number">1960</span>      <span class="number">2010</span>      <span class="number">1910</span>      <span class="number">1960</span>      <span class="number">2010</span></span><br><span class="line">last_letter                                                            </span><br><span class="line">a            <span class="number">0.273390</span>  <span class="number">0.341853</span>  <span class="number">0.381240</span>  <span class="number">0.005031</span>  <span class="number">0.002440</span>  <span class="number">0.014980</span></span><br><span class="line">b                 NaN  <span class="number">0.000343</span>  <span class="number">0.000256</span>  <span class="number">0.002116</span>  <span class="number">0.001834</span>  <span class="number">0.020470</span></span><br><span class="line">c            <span class="number">0.000013</span>  <span class="number">0.000024</span>  <span class="number">0.000538</span>  <span class="number">0.002482</span>  <span class="number">0.007257</span>  <span class="number">0.012181</span></span><br><span class="line">d            <span class="number">0.017028</span>  <span class="number">0.001844</span>  <span class="number">0.001482</span>  <span class="number">0.113858</span>  <span class="number">0.122908</span>  <span class="number">0.023387</span></span><br><span class="line">e            <span class="number">0.336941</span>  <span class="number">0.215133</span>  <span class="number">0.178415</span>  <span class="number">0.147556</span>  <span class="number">0.083853</span>  <span class="number">0.067959</span></span><br><span class="line"><span class="meta">... </span>              ...       ...       ...       ...       ...       ...</span><br><span class="line">v                 NaN  <span class="number">0.000060</span>  <span class="number">0.000117</span>  <span class="number">0.000113</span></span><br><span class="line"><span class="number">0.000037</span>  <span class="number">0.001434</span></span><br><span class="line">w            <span class="number">0.000020</span>  <span class="number">0.000031</span>  <span class="number">0.001182</span>  <span class="number">0.006329</span>  <span class="number">0.007711</span>  <span class="number">0.016148</span></span><br><span class="line">x            <span class="number">0.000015</span>  <span class="number">0.000037</span>  <span class="number">0.000727</span>  <span class="number">0.003965</span>  <span class="number">0.001851</span>  <span class="number">0.008614</span></span><br><span class="line">y            <span class="number">0.110972</span>  <span class="number">0.152569</span>  <span class="number">0.116828</span>  <span class="number">0.077349</span>  <span class="number">0.160987</span>  <span class="number">0.058168</span></span><br><span class="line">z            <span class="number">0.002439</span>  <span class="number">0.000659</span>  <span class="number">0.000704</span>  <span class="number">0.000170</span>  <span class="number">0.000184</span>  <span class="number">0.001831</span></span><br><span class="line">[<span class="number">26</span> rows x <span class="number">6</span> columns]</span><br></pre></td></tr></table></figure></p>
<p>有了这个字母比例数据之后，就可以生成一张各年度各性别的条形图了，如图14-8所示：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">fig, axes = plt.subplots(<span class="number">2</span>, <span class="number">1</span>, figsize=(<span class="number">10</span>, <span class="number">8</span>))</span><br><span class="line">letter_prop[<span class="string">'M'</span>].plot(kind=<span class="string">'bar'</span>, rot=<span class="number">0</span>, ax=axes[<span class="number">0</span>], title=<span class="string">'Male'</span>)</span><br><span class="line">letter_prop[<span class="string">'F'</span>].plot(kind=<span class="string">'bar'</span>, rot=<span class="number">0</span>, ax=axes[<span class="number">1</span>], title=<span class="string">'Female'</span>,</span><br><span class="line">                      legend=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure></p>
<p><img src="http://upload-images.jianshu.io/upload_images/7178691-67686f38e66ef5f1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图14-8 男孩女孩名字中各个末字母的比例"></p>
<p>可以看出，从20世纪60年代开始，以字母”n”结尾的男孩名字出现了显著的增长。回到之前创建的那个完整表，按年度和性别对其进行规范化处理，并在男孩名字中选取几个字母，最后进行转置以便将各个列做成一个时间序列：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">138</span>]: letter_prop = table / table.sum()</span><br><span class="line"></span><br><span class="line">In [<span class="number">139</span>]: dny_ts = letter_prop.loc[[<span class="string">'d'</span>, <span class="string">'n'</span>, <span class="string">'y'</span>], <span class="string">'M'</span>].T</span><br><span class="line"></span><br><span class="line">In [<span class="number">140</span>]: dny_ts.head()</span><br><span class="line">Out[<span class="number">140</span>]: </span><br><span class="line">last_letter         d         n         y</span><br><span class="line">year                                     </span><br><span class="line"><span class="number">1880</span>         <span class="number">0.083055</span>  <span class="number">0.153213</span>  <span class="number">0.075760</span></span><br><span class="line"><span class="number">1881</span>         <span class="number">0.083247</span>  <span class="number">0.153214</span>  <span class="number">0.077451</span></span><br><span class="line"><span class="number">1882</span>         <span class="number">0.085340</span>  <span class="number">0.149560</span>  <span class="number">0.077537</span></span><br><span class="line"><span class="number">1883</span>         <span class="number">0.084066</span>  <span class="number">0.151646</span>  <span class="number">0.079144</span></span><br><span class="line"><span class="number">1884</span>         <span class="number">0.086120</span>  <span class="number">0.149915</span>  <span class="number">0.080405</span></span><br></pre></td></tr></table></figure></p>
<p>有了这个时间序列的DataFrame之后，就可以通过其plot方法绘制出一张趋势图了（如图14-9所示）：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">143</span>]: dny_ts.plot()</span><br></pre></td></tr></table></figure></p>
<p><img src="http://upload-images.jianshu.io/upload_images/7178691-51c431b2490424c2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图14-9 各年出生的男孩中名字以d/n/y结尾的人数比例"></p>
<h2 id="变成女孩名字的男孩名字（以及相反的情况）"><a href="#变成女孩名字的男孩名字（以及相反的情况）" class="headerlink" title="变成女孩名字的男孩名字（以及相反的情况）"></a>变成女孩名字的男孩名字（以及相反的情况）</h2><p>另一个有趣的趋势是，早年流行于男孩的名字近年来“变性了”，例如Lesley或Leslie。回到top1000数据集，找出其中以”lesl”开头的一组名字：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">144</span>]: all_names = pd.Series(top1000.name.unique())</span><br><span class="line"></span><br><span class="line">In [<span class="number">145</span>]: lesley_like = all_names[all_names.str.lower().str.contains(<span class="string">'lesl'</span>)]</span><br><span class="line"></span><br><span class="line">In [<span class="number">146</span>]: lesley_like</span><br><span class="line">Out[<span class="number">146</span>]: </span><br><span class="line"><span class="number">632</span>     Leslie</span><br><span class="line"><span class="number">2294</span>    Lesley</span><br><span class="line"><span class="number">4262</span>    Leslee</span><br><span class="line"><span class="number">4728</span>     Lesli</span><br><span class="line"><span class="number">6103</span>     Lesly</span><br><span class="line">dtype: object</span><br></pre></td></tr></table></figure>
<p>然后利用这个结果过滤其他的名字，并按名字分组计算出生数以查看相对频率：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">147</span>]: filtered = top1000[top1000.name.isin(lesley_like)]</span><br><span class="line"></span><br><span class="line">In [<span class="number">148</span>]: filtered.groupby(<span class="string">'name'</span>).births.sum()</span><br><span class="line">Out[<span class="number">148</span>]: </span><br><span class="line">name</span><br><span class="line">Leslee      <span class="number">1082</span></span><br><span class="line">Lesley     <span class="number">35022</span></span><br><span class="line">Lesli        <span class="number">929</span></span><br><span class="line">Leslie    <span class="number">370429</span></span><br><span class="line">Lesly      <span class="number">10067</span></span><br><span class="line">Name: births, dtype: int64</span><br></pre></td></tr></table></figure></p>
<p>接下来，我们按性别和年度进行聚合，并按年度进行规范化处理：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">149</span>]: table = filtered.pivot_table(<span class="string">'births'</span>, index=<span class="string">'year'</span>,</span><br><span class="line">   .....:                              columns=<span class="string">'sex'</span>, aggfunc=<span class="string">'sum'</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">150</span>]: table = table.div(table.sum(<span class="number">1</span>), axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">151</span>]: table.tail()</span><br><span class="line">Out[<span class="number">151</span>]: </span><br><span class="line">sex     F   M</span><br><span class="line">year         </span><br><span class="line"><span class="number">2006</span>  <span class="number">1.0</span> NaN</span><br><span class="line"><span class="number">2007</span>  <span class="number">1.0</span> NaN</span><br><span class="line"><span class="number">2008</span>  <span class="number">1.0</span> NaN</span><br><span class="line"><span class="number">2009</span>  <span class="number">1.0</span> NaN</span><br><span class="line"><span class="number">2010</span>  <span class="number">1.0</span> NaN</span><br></pre></td></tr></table></figure></p>
<p>最后，就可以轻松绘制一张分性别的年度曲线图了（如图2-10所示）：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">153</span>]: table.plot(style=&#123;<span class="string">'M'</span>: <span class="string">'k-'</span>, <span class="string">'F'</span>: <span class="string">'k--'</span>&#125;)</span><br></pre></td></tr></table></figure></p>
<p><img src="http://upload-images.jianshu.io/upload_images/7178691-b99d98f8bb5fc695.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图14-10 各年度使用“Lesley型”名字的男女比例"></p>
<h1 id="14-4-USDA食品数据库"><a href="#14-4-USDA食品数据库" class="headerlink" title="14.4 USDA食品数据库"></a>14.4 USDA食品数据库</h1><p>美国农业部（USDA）制作了一份有关食物营养信息的数据库。Ashley Williams制作了该数据的JSON版（<a href="http://ashleyw.co.uk/project/food-nutrient-database）。其中的记录如下所示：" target="_blank" rel="noopener">http://ashleyw.co.uk/project/food-nutrient-database）。其中的记录如下所示：</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="string">"id"</span>: <span class="number">21441</span>,</span><br><span class="line">  <span class="string">"description"</span>: <span class="string">"KENTUCKY FRIED CHICKEN, Fried Chicken, EXTRA CRISPY,</span></span><br><span class="line"><span class="string">Wing, meat and skin with breading"</span>,</span><br><span class="line">  <span class="string">"tags"</span>: [<span class="string">"KFC"</span>],</span><br><span class="line">  <span class="string">"manufacturer"</span>: <span class="string">"Kentucky Fried Chicken"</span>,</span><br><span class="line"><span class="string">"group"</span>: <span class="string">"Fast Foods"</span>,</span><br><span class="line">  <span class="string">"portions"</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="string">"amount"</span>: <span class="number">1</span>,</span><br><span class="line">      <span class="string">"unit"</span>: <span class="string">"wing, with skin"</span>,</span><br><span class="line">      <span class="string">"grams"</span>: <span class="number">68.0</span></span><br><span class="line">    &#125;,</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line">  ],</span><br><span class="line">  <span class="string">"nutrients"</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="string">"value"</span>: <span class="number">20.8</span>,</span><br><span class="line">      <span class="string">"units"</span>: <span class="string">"g"</span>,</span><br><span class="line">      <span class="string">"description"</span>: <span class="string">"Protein"</span>,</span><br><span class="line">      <span class="string">"group"</span>: <span class="string">"Composition"</span></span><br><span class="line">    &#125;,</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>每种食物都带有若干标识性属性以及两个有关营养成分和分量的列表。这种形式的数据不是很适合分析工作，因此我们需要做一些规整化以使其具有更好用的形式。</p>
<p>从上面列举的那个网址下载并解压数据之后，你可以用任何喜欢的JSON库将其加载到Python中。我用的是Python内置的json模块：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">154</span>]: <span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">In [<span class="number">155</span>]: db = json.load(open(<span class="string">'datasets/usda_food/database.json'</span>))</span><br><span class="line"></span><br><span class="line">In [<span class="number">156</span>]: len(db)</span><br><span class="line">Out[<span class="number">156</span>]: <span class="number">6636</span></span><br></pre></td></tr></table></figure></p>
<p>db中的每个条目都是一个含有某种食物全部数据的字典。nutrients字段是一个字典列表，其中的每个字典对应一种营养成分：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">157</span>]: db[<span class="number">0</span>].keys()</span><br><span class="line">Out[<span class="number">157</span>]: dict_keys([<span class="string">'id'</span>, <span class="string">'description'</span>, <span class="string">'tags'</span>, <span class="string">'manufacturer'</span>, <span class="string">'group'</span>, <span class="string">'porti</span></span><br><span class="line"><span class="string">ons'</span>, <span class="string">'nutrients'</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">158</span>]: db[<span class="number">0</span>][<span class="string">'nutrients'</span>][<span class="number">0</span>]</span><br><span class="line">Out[<span class="number">158</span>]: </span><br><span class="line">&#123;<span class="string">'description'</span>: <span class="string">'Protein'</span>,</span><br><span class="line"> <span class="string">'group'</span>: <span class="string">'Composition'</span>,</span><br><span class="line"> <span class="string">'units'</span>: <span class="string">'g'</span>,</span><br><span class="line"> <span class="string">'value'</span>: <span class="number">25.18</span>&#125;</span><br><span class="line"></span><br><span class="line">In [<span class="number">159</span>]: nutrients = pd.DataFrame(db[<span class="number">0</span>][<span class="string">'nutrients'</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">160</span>]: nutrients[:<span class="number">7</span>]</span><br><span class="line">Out[<span class="number">160</span>]: </span><br><span class="line">                   description        group units    value</span><br><span class="line"><span class="number">0</span>                      Protein  Composition     g    <span class="number">25.18</span></span><br><span class="line"><span class="number">1</span>            Total lipid (fat)  Composition     g    <span class="number">29.20</span></span><br><span class="line"><span class="number">2</span>  Carbohydrate, by difference  Composition     g     <span class="number">3.06</span></span><br><span class="line"><span class="number">3</span>                          Ash        Other     g     <span class="number">3.28</span></span><br><span class="line"><span class="number">4</span>                       Energy       Energy  kcal   <span class="number">376.00</span></span><br><span class="line"><span class="number">5</span>                        Water  Composition     g    <span class="number">39.28</span></span><br><span class="line"><span class="number">6</span>                       Energy       Energy    kJ  <span class="number">1573.00</span></span><br></pre></td></tr></table></figure></p>
<p>在将字典列表转换为DataFrame时，可以只抽取其中的一部分字段。这里，我们将取出食物的名称、分类、编号以及制造商等信息：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">161</span>]: info_keys = [<span class="string">'description'</span>, <span class="string">'group'</span>, <span class="string">'id'</span>, <span class="string">'manufacturer'</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">162</span>]: info = pd.DataFrame(db, columns=info_keys)</span><br><span class="line"></span><br><span class="line">In [<span class="number">163</span>]: info[:<span class="number">5</span>]</span><br><span class="line">Out[<span class="number">163</span>]: </span><br><span class="line">                          description                   group    id  \</span><br><span class="line"><span class="number">0</span>                     Cheese, caraway  Dairy <span class="keyword">and</span> Egg Products  <span class="number">1008</span>   </span><br><span class="line"><span class="number">1</span>                     Cheese, cheddar  Dairy <span class="keyword">and</span> Egg Products  <span class="number">1009</span></span><br><span class="line"><span class="number">2</span>                        Cheese, edam  Dairy <span class="keyword">and</span> Egg Products  <span class="number">1018</span>   </span><br><span class="line"><span class="number">3</span>                        Cheese, feta  Dairy <span class="keyword">and</span> Egg Products  <span class="number">1019</span>   </span><br><span class="line"><span class="number">4</span>  Cheese, mozzarella, part skim milk  Dairy <span class="keyword">and</span> Egg Products  <span class="number">1028</span>   </span><br><span class="line">  manufacturer  </span><br><span class="line"><span class="number">0</span>               </span><br><span class="line"><span class="number">1</span>               </span><br><span class="line"><span class="number">2</span>               </span><br><span class="line"><span class="number">3</span>               </span><br><span class="line"><span class="number">4</span>               </span><br><span class="line"></span><br><span class="line">In [<span class="number">164</span>]: info.info()</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">pandas</span>.<span class="title">core</span>.<span class="title">frame</span>.<span class="title">DataFrame</span>'&gt;</span></span><br><span class="line"><span class="class"><span class="title">RangeIndex</span>:</span> <span class="number">6636</span> entries, <span class="number">0</span> to <span class="number">6635</span></span><br><span class="line">Data columns (total <span class="number">4</span> columns):</span><br><span class="line">description     <span class="number">6636</span> non-null object</span><br><span class="line">group           <span class="number">6636</span> non-null object</span><br><span class="line">id              <span class="number">6636</span> non-null int64</span><br><span class="line">manufacturer    <span class="number">5195</span> non-null object</span><br><span class="line">dtypes: int64(<span class="number">1</span>), object(<span class="number">3</span>)</span><br><span class="line">memory usage: <span class="number">207.5</span>+ KB</span><br></pre></td></tr></table></figure>
<p>通过value_counts，你可以查看食物类别的分布情况：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">165</span>]: pd.value_counts(info.group)[:<span class="number">10</span>]</span><br><span class="line">Out[<span class="number">165</span>]: </span><br><span class="line">Vegetables <span class="keyword">and</span> Vegetable Products    <span class="number">812</span></span><br><span class="line">Beef Products                        <span class="number">618</span></span><br><span class="line">Baked Products                       <span class="number">496</span></span><br><span class="line">Breakfast Cereals                    <span class="number">403</span></span><br><span class="line">Fast Foods                           <span class="number">365</span></span><br><span class="line">Legumes <span class="keyword">and</span> Legume Products          <span class="number">365</span></span><br><span class="line">Lamb, Veal, <span class="keyword">and</span> Game Products        <span class="number">345</span></span><br><span class="line">Sweets                               <span class="number">341</span></span><br><span class="line">Pork Products                        <span class="number">328</span></span><br><span class="line">Fruits <span class="keyword">and</span> Fruit Juices              <span class="number">328</span></span><br><span class="line">Name: group, dtype: int64</span><br></pre></td></tr></table></figure></p>
<p>现在，为了对全部营养数据做一些分析，最简单的办法是将所有食物的营养成分整合到一个大表中。我们分几个步骤来实现该目的。首先，将各食物的营养成分列表转换为一个DataFrame，并添加一个表示编号的列，然后将该DataFrame添加到一个列表中。最后通过concat将这些东西连接起来就可以了：</p>
<p>顺利的话，nutrients的结果是：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">167</span>]: nutrients</span><br><span class="line">Out[<span class="number">167</span>]: </span><br><span class="line">                               description        group units    value     id</span><br><span class="line"><span class="number">0</span>                                  Protein  Composition     g   <span class="number">25.180</span>   <span class="number">1008</span></span><br><span class="line"><span class="number">1</span>                        Total lipid (fat)  Composition     g   <span class="number">29.200</span>   <span class="number">1008</span></span><br><span class="line"><span class="number">2</span>              Carbohydrate, by difference  Composition     g    <span class="number">3.060</span>   <span class="number">1008</span></span><br><span class="line"><span class="number">3</span>                                      Ash        Other     g    <span class="number">3.280</span>   <span class="number">1008</span></span><br><span class="line"><span class="number">4</span>                                   Energy       Energy  kcal  <span class="number">376.000</span>   <span class="number">1008</span></span><br><span class="line"><span class="meta">... </span>                                   ...          ...</span><br><span class="line"><span class="meta">... </span>     ...    ...</span><br><span class="line"><span class="number">389350</span>                 Vitamin B<span class="number">-12</span>, added     Vitamins   mcg    <span class="number">0.000</span>  <span class="number">43546</span></span><br><span class="line"><span class="number">389351</span>                         Cholesterol        Other    mg    <span class="number">0.000</span>  <span class="number">43546</span></span><br><span class="line"><span class="number">389352</span>        Fatty acids, total saturated        Other     g    <span class="number">0.072</span>  <span class="number">43546</span></span><br><span class="line"><span class="number">389353</span>  Fatty acids, total monounsaturated        Other     g    <span class="number">0.028</span>  <span class="number">43546</span></span><br><span class="line"><span class="number">389354</span>  Fatty acids, total polyunsaturated        Other     g    <span class="number">0.041</span>  <span class="number">43546</span></span><br><span class="line">[<span class="number">389355</span> rows x <span class="number">5</span> columns]</span><br></pre></td></tr></table></figure></p>
<p>我发现这个DataFrame中无论如何都会有一些重复项，所以直接丢弃就可以了：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">168</span>]: nutrients.duplicated().sum()  <span class="comment"># number of duplicates</span></span><br><span class="line">Out[<span class="number">168</span>]: <span class="number">14179</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">169</span>]: nutrients = nutrients.drop_duplicates()</span><br></pre></td></tr></table></figure></p>
<p>由于两个DataFrame对象中都有”group”和”description”，所以为了明确到底谁是谁，我们需要对它们进行重命名：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">170</span>]: col_mapping = &#123;<span class="string">'description'</span> : <span class="string">'food'</span>,</span><br><span class="line">   .....:                <span class="string">'group'</span>       : <span class="string">'fgroup'</span>&#125;</span><br><span class="line"></span><br><span class="line">In [<span class="number">171</span>]: info = info.rename(columns=col_mapping, copy=<span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">172</span>]: info.info()</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">pandas</span>.<span class="title">core</span>.<span class="title">frame</span>.<span class="title">DataFrame</span>'&gt;</span></span><br><span class="line"><span class="class"><span class="title">RangeIndex</span>:</span> <span class="number">6636</span> entries, <span class="number">0</span> to <span class="number">6635</span></span><br><span class="line">Data columns (total <span class="number">4</span> columns):</span><br><span class="line">food            <span class="number">6636</span> non-null object</span><br><span class="line">fgroup          <span class="number">6636</span> non-null object</span><br><span class="line">id              <span class="number">6636</span> non-null int64</span><br><span class="line">manufacturer    <span class="number">5195</span> non-null object</span><br><span class="line">dtypes: int64(<span class="number">1</span>), object(<span class="number">3</span>)</span><br><span class="line">memory usage: <span class="number">207.5</span>+ KB</span><br><span class="line"></span><br><span class="line">In [<span class="number">173</span>]: col_mapping = &#123;<span class="string">'description'</span> : <span class="string">'nutrient'</span>,</span><br><span class="line">   .....:                <span class="string">'group'</span> : <span class="string">'nutgroup'</span>&#125;</span><br><span class="line">In [<span class="number">174</span>]: nutrients = nutrients.rename(columns=col_mapping, copy=<span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">175</span>]: nutrients</span><br><span class="line">Out[<span class="number">175</span>]: </span><br><span class="line">                                  nutrient     nutgroup units    value     id</span><br><span class="line"><span class="number">0</span>                                  Protein  Composition     g   <span class="number">25.180</span>   <span class="number">1008</span></span><br><span class="line"><span class="number">1</span>                        Total lipid (fat)  Composition     g   <span class="number">29.200</span>   <span class="number">1008</span></span><br><span class="line"><span class="number">2</span>              Carbohydrate, by difference  Composition     g    <span class="number">3.060</span>   <span class="number">1008</span></span><br><span class="line"><span class="number">3</span>                                      Ash        Other     g    <span class="number">3.280</span>   <span class="number">1008</span></span><br><span class="line"><span class="number">4</span>                                   Energy       Energy  kcal  <span class="number">376.000</span>   <span class="number">1008</span></span><br><span class="line"><span class="meta">... </span>                                   ...          ...   ...      ...    ...</span><br><span class="line"><span class="number">389350</span>                 Vitamin B<span class="number">-12</span>, added     Vitamins   mcg    <span class="number">0.000</span>  <span class="number">43546</span></span><br><span class="line"><span class="number">389351</span>                         Cholesterol        Other    mg    <span class="number">0.000</span>  <span class="number">43546</span></span><br><span class="line"><span class="number">389352</span>        Fatty acids, total saturated        Other     g    <span class="number">0.072</span>  <span class="number">43546</span></span><br><span class="line"><span class="number">389353</span>  Fatty acids, total monounsaturated        Other     g    <span class="number">0.028</span>  <span class="number">43546</span></span><br><span class="line"><span class="number">389354</span>  Fatty acids, total polyunsaturated        Other     g    <span class="number">0.041</span>  <span class="number">43546</span></span><br><span class="line">[<span class="number">375176</span> rows x <span class="number">5</span> columns]</span><br></pre></td></tr></table></figure></p>
<p>做完这些，就可以将info跟nutrients合并起来：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">176</span>]: ndata = pd.merge(nutrients, info, on=<span class="string">'id'</span>, how=<span class="string">'outer'</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">177</span>]: ndata.info()</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">pandas</span>.<span class="title">core</span>.<span class="title">frame</span>.<span class="title">DataFrame</span>'&gt;</span></span><br><span class="line"><span class="class"><span class="title">Int64Index</span>:</span> <span class="number">375176</span> entries, <span class="number">0</span> to <span class="number">375175</span></span><br><span class="line">Data columns (total <span class="number">8</span> columns):</span><br><span class="line">nutrient        <span class="number">375176</span> non-null object</span><br><span class="line">nutgroup        <span class="number">375176</span> non-null object</span><br><span class="line">units           <span class="number">375176</span> non-null object</span><br><span class="line">value           <span class="number">375176</span> non-null float64</span><br><span class="line">id              <span class="number">375176</span> non-null int64</span><br><span class="line">food            <span class="number">375176</span> non-null object</span><br><span class="line">fgroup          <span class="number">375176</span> non-null object</span><br><span class="line">manufacturer    <span class="number">293054</span> non-null object</span><br><span class="line">dtypes: float64(<span class="number">1</span>), int64(<span class="number">1</span>), object(<span class="number">6</span>)</span><br><span class="line">memory usage: <span class="number">25.8</span>+ MB</span><br><span class="line"></span><br><span class="line">In [<span class="number">178</span>]: ndata.iloc[<span class="number">30000</span>]</span><br><span class="line">Out[<span class="number">178</span>]: </span><br><span class="line">nutrient                                       Glycine</span><br><span class="line">nutgroup                                   Amino Acids</span><br><span class="line">units                                                g</span><br><span class="line">value                                             <span class="number">0.04</span></span><br><span class="line">id                                                <span class="number">6158</span></span><br><span class="line">food            Soup, tomato bisque, canned, condensed</span><br><span class="line">fgroup                      Soups, Sauces, <span class="keyword">and</span> Gravies</span><br><span class="line">manufacturer                                          </span><br><span class="line">Name: <span class="number">30000</span>, dtype: object</span><br></pre></td></tr></table></figure></p>
<p>我们现在可以根据食物分类和营养类型画出一张中位值图（如图14-11所示）：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">180</span>]: result = ndata.groupby([<span class="string">'nutrient'</span>, <span class="string">'fgroup'</span>])[<span class="string">'value'</span>].quantile(<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">181</span>]: result[<span class="string">'Zinc, Zn'</span>].sort_values().plot(kind=<span class="string">'barh'</span>)</span><br></pre></td></tr></table></figure></p>
<p><img src="http://upload-images.jianshu.io/upload_images/7178691-99b176d022a444c0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图片14-11 根据营养分类得出的锌中位值"></p>
<p>只要稍微动一动脑子，就可以发现各营养成分最为丰富的食物是什么了：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">by_nutrient = ndata.groupby([<span class="string">'nutgroup'</span>, <span class="string">'nutrient'</span>])</span><br><span class="line"></span><br><span class="line">get_maximum = <span class="keyword">lambda</span> x: x.loc[x.value.idxmax()]</span><br><span class="line">get_minimum = <span class="keyword">lambda</span> x: x.loc[x.value.idxmin()]</span><br><span class="line"></span><br><span class="line">max_foods = by_nutrient.apply(get_maximum)[[<span class="string">'value'</span>, <span class="string">'food'</span>]]</span><br><span class="line"></span><br><span class="line"><span class="comment"># make the food a little smaller</span></span><br><span class="line">max_foods.food = max_foods.food.str[:<span class="number">50</span>]</span><br></pre></td></tr></table></figure></p>
<p>由于得到的DataFrame很大，所以不方便在书里面全部打印出来。这里只给出”Amino Acids”营养分组：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">183</span>]: max_foods.loc[<span class="string">'Amino Acids'</span>][<span class="string">'food'</span>]</span><br><span class="line">Out[<span class="number">183</span>]: </span><br><span class="line">nutrient</span><br><span class="line">Alanine                          Gelatins, dry powder, unsweetened</span><br><span class="line">Arginine                              Seeds, sesame flour, low-fat</span><br><span class="line">Aspartic acid                                  Soy protein isolate</span><br><span class="line">Cystine               Seeds, cottonseed flour, low fat (glandless)</span><br><span class="line">Glutamic acid                                  Soy protein isolate</span><br><span class="line">                                       ...                        </span><br><span class="line">Serine           Soy protein isolate, PROTEIN TECHNOLOGIES INTE...</span><br><span class="line">Threonine        Soy protein isolate, PROTEIN TECHNOLOGIES INTE...</span><br><span class="line">Tryptophan        Sea lion, Steller, meat <span class="keyword">with</span> fat (Alaska Native)</span><br><span class="line">Tyrosine         Soy protein isolate, PROTEIN TECHNOLOGIES INTE...</span><br><span class="line">Valine           Soy protein isolate, PROTEIN TECHNOLOGIES INTE...</span><br><span class="line">Name: food, Length: <span class="number">19</span>, dtype: object</span><br></pre></td></tr></table></figure></p>
<h1 id="14-5-2012联邦选举委员会数据库"><a href="#14-5-2012联邦选举委员会数据库" class="headerlink" title="14.5 2012联邦选举委员会数据库"></a>14.5 2012联邦选举委员会数据库</h1><p>美国联邦选举委员会发布了有关政治竞选赞助方面的数据。其中包括赞助者的姓名、职业、雇主、地址以及出资额等信息。我们对2012年美国总统大选的数据集比较感兴趣（<a href="http://www.fec.gov/disclosurep/PDownload.do）。我在2012年6月下载的数据集是一个150MB的CSV文件（P00000001-ALL.csv），我们先用pandas.read_csv将其加载进来：" target="_blank" rel="noopener">http://www.fec.gov/disclosurep/PDownload.do）。我在2012年6月下载的数据集是一个150MB的CSV文件（P00000001-ALL.csv），我们先用pandas.read_csv将其加载进来：</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">184</span>]: fec = pd.read_csv(<span class="string">'datasets/fec/P00000001-ALL.csv'</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">185</span>]: fec.info()</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">pandas</span>.<span class="title">core</span>.<span class="title">frame</span>.<span class="title">DataFrame</span>'&gt;</span></span><br><span class="line"><span class="class"><span class="title">RangeIndex</span>:</span> <span class="number">1001731</span> entries, <span class="number">0</span> to <span class="number">1001730</span></span><br><span class="line">Data columns (total <span class="number">16</span> columns):</span><br><span class="line">cmte_id              <span class="number">1001731</span> non-null object</span><br><span class="line">cand_id              <span class="number">1001731</span> non-null object</span><br><span class="line">cand_nm              <span class="number">1001731</span> non-null object</span><br><span class="line">contbr_nm            <span class="number">1001731</span> non-null object</span><br><span class="line">contbr_city          <span class="number">1001712</span> non-null object</span><br><span class="line">contbr_st            <span class="number">1001727</span> non-null object</span><br><span class="line">contbr_zip           <span class="number">1001620</span> non-null object</span><br><span class="line">contbr_employer      <span class="number">988002</span> non-null object</span><br><span class="line">contbr_occupation    <span class="number">993301</span> non-null object</span><br><span class="line">contb_receipt_amt    <span class="number">1001731</span> non-null float64</span><br><span class="line">contb_receipt_dt     <span class="number">1001731</span> non-null object</span><br><span class="line">receipt_desc         <span class="number">14166</span> non-null object</span><br><span class="line">memo_cd              <span class="number">92482</span> non-null object</span><br><span class="line">memo_text            <span class="number">97770</span> non-null object</span><br><span class="line">form_tp              <span class="number">1001731</span> non-null object</span><br><span class="line">file_num             <span class="number">1001731</span> non-null int64</span><br><span class="line">dtypes: float64(<span class="number">1</span>), int64(<span class="number">1</span>), object(<span class="number">14</span>)</span><br><span class="line">memory usage: <span class="number">122.3</span>+ MB</span><br></pre></td></tr></table></figure>
<p>该DataFrame中的记录如下所示：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">186</span>]: fec.iloc[<span class="number">123456</span>]</span><br><span class="line">Out[<span class="number">186</span>]: </span><br><span class="line">cmte_id             C00431445</span><br><span class="line">cand_id             P80003338</span><br><span class="line">cand_nm         Obama, Barack</span><br><span class="line">contbr_nm         ELLMAN, IRA</span><br><span class="line">contbr_city             TEMPE</span><br><span class="line">                    ...      </span><br><span class="line">receipt_desc              NaN</span><br><span class="line">memo_cd                   NaN</span><br><span class="line">memo_text                 NaN</span><br><span class="line">form_tp                 SA17A</span><br><span class="line">file_num               <span class="number">772372</span></span><br><span class="line">Name: <span class="number">123456</span>, Length: <span class="number">16</span>, dtype: object</span><br></pre></td></tr></table></figure></p>
<p>你可能已经想出了许多办法从这些竞选赞助数据中抽取有关赞助人和赞助模式的统计信息。我将在接下来的内容中介绍几种不同的分析工作（运用到目前为止已经学到的方法）。</p>
<p>不难看出，该数据中没有党派信息，因此最好把它加进去。通过unique，你可以获取全部的候选人名单：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">187</span>]: unique_cands = fec.cand_nm.unique()</span><br><span class="line"></span><br><span class="line">In [<span class="number">188</span>]: unique_cands</span><br><span class="line">Out[<span class="number">188</span>]: </span><br><span class="line">array([<span class="string">'Bachmann, Michelle'</span>, <span class="string">'Romney, Mitt'</span>, <span class="string">'Obama, Barack'</span>,</span><br><span class="line">       <span class="string">"Roemer, Charles E. 'Buddy' III"</span>, <span class="string">'Pawlenty, Timothy'</span>,</span><br><span class="line">       <span class="string">'Johnson, Gary Earl'</span>, <span class="string">'Paul, Ron'</span>, <span class="string">'Santorum, Rick'</span>, <span class="string">'Cain, Herman'</span>,</span><br><span class="line">       <span class="string">'Gingrich, Newt'</span>, <span class="string">'McCotter, Thaddeus G'</span>, <span class="string">'Huntsman, Jon'</span>,</span><br><span class="line">       <span class="string">'Perry, Rick'</span>], dtype=object)</span><br><span class="line"></span><br><span class="line">In [<span class="number">189</span>]: unique_cands[<span class="number">2</span>]</span><br><span class="line">Out[<span class="number">189</span>]: <span class="string">'Obama, Barack'</span></span><br></pre></td></tr></table></figure></p>
<p>指明党派信息的方法之一是使用字典：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">parties = &#123;<span class="string">'Bachmann, Michelle'</span>: <span class="string">'Republican'</span>,</span><br><span class="line">           <span class="string">'Cain, Herman'</span>: <span class="string">'Republican'</span>,</span><br><span class="line">           <span class="string">'Gingrich, Newt'</span>: <span class="string">'Republican'</span>,</span><br><span class="line">           <span class="string">'Huntsman, Jon'</span>: <span class="string">'Republican'</span>,</span><br><span class="line">           <span class="string">'Johnson, Gary Earl'</span>: <span class="string">'Republican'</span>,</span><br><span class="line">           <span class="string">'McCotter, Thaddeus G'</span>: <span class="string">'Republican'</span>,</span><br><span class="line">           <span class="string">'Obama, Barack'</span>: <span class="string">'Democrat'</span>,</span><br><span class="line">           <span class="string">'Paul, Ron'</span>: <span class="string">'Republican'</span>,</span><br><span class="line">           <span class="string">'Pawlenty, Timothy'</span>: <span class="string">'Republican'</span>,</span><br><span class="line">           <span class="string">'Perry, Rick'</span>: <span class="string">'Republican'</span>,</span><br><span class="line">           <span class="string">"Roemer, Charles E. 'Buddy' III"</span>: <span class="string">'Republican'</span>,</span><br><span class="line">           <span class="string">'Romney, Mitt'</span>: <span class="string">'Republican'</span>,</span><br><span class="line">           <span class="string">'Santorum, Rick'</span>: <span class="string">'Republican'</span>&#125;</span><br></pre></td></tr></table></figure></p>
<p>现在，通过这个映射以及Series对象的map方法，你可以根据候选人姓名得到一组党派信息：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">191</span>]: fec.cand_nm[<span class="number">123456</span>:<span class="number">123461</span>]</span><br><span class="line">Out[<span class="number">191</span>]: </span><br><span class="line"><span class="number">123456</span>    Obama, Barack</span><br><span class="line"><span class="number">123457</span>    Obama, Barack</span><br><span class="line"><span class="number">123458</span>    Obama, Barack</span><br><span class="line"><span class="number">123459</span>    Obama, Barack</span><br><span class="line"><span class="number">123460</span>    Obama, Barack</span><br><span class="line">Name: cand_nm, dtype: object</span><br><span class="line"></span><br><span class="line">In [<span class="number">192</span>]: fec.cand_nm[<span class="number">123456</span>:<span class="number">123461</span>].map(parties)</span><br><span class="line">Out[<span class="number">192</span>]: </span><br><span class="line"><span class="number">123456</span>    Democrat</span><br><span class="line"><span class="number">123457</span>    Democrat</span><br><span class="line"><span class="number">123458</span>    Democrat</span><br><span class="line"><span class="number">123459</span>    Democrat</span><br><span class="line"><span class="number">123460</span>    Democrat</span><br><span class="line">Name: cand_nm, dtype: object</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add it as a column</span></span><br><span class="line">In [<span class="number">193</span>]: fec[<span class="string">'party'</span>] = fec.cand_nm.map(parties)</span><br><span class="line"></span><br><span class="line">In [<span class="number">194</span>]: fec[<span class="string">'party'</span>].value_counts()</span><br><span class="line">Out[<span class="number">194</span>]: </span><br><span class="line">Democrat      <span class="number">593746</span></span><br><span class="line">Republican    <span class="number">407985</span></span><br><span class="line">Name: party, dtype: int64</span><br></pre></td></tr></table></figure></p>
<p>这里有两个需要注意的地方。第一，该数据既包括赞助也包括退款（负的出资额）：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">195</span>]: (fec.contb_receipt_amt &gt; <span class="number">0</span>).value_counts()</span><br><span class="line">Out[<span class="number">195</span>]: </span><br><span class="line"><span class="keyword">True</span>     <span class="number">991475</span></span><br><span class="line"><span class="keyword">False</span>     <span class="number">10256</span></span><br><span class="line">Name: contb_receipt_amt, dtype: int64</span><br></pre></td></tr></table></figure></p>
<p>为了简化分析过程，我限定该数据集只能有正的出资额：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">196</span>]: fec = fec[fec.contb_receipt_amt &gt; <span class="number">0</span>]</span><br></pre></td></tr></table></figure></p>
<p>由于Barack Obama和Mitt Romney是最主要的两名候选人，所以我还专门准备了一个子集，只包含针对他们两人的竞选活动的赞助信息：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">197</span>]: fec_mrbo = fec[fec.cand_nm.isin([<span class="string">'Obama, Barack'</span>,<span class="string">'Romney, Mitt'</span>])]</span><br></pre></td></tr></table></figure></p>
<h2 id="根据职业和雇主统计赞助信息"><a href="#根据职业和雇主统计赞助信息" class="headerlink" title="根据职业和雇主统计赞助信息"></a>根据职业和雇主统计赞助信息</h2><p>基于职业的赞助信息统计是另一种经常被研究的统计任务。例如，律师们更倾向于资助民主党，而企业主则更倾向于资助共和党。你可以不相信我，自己看那些数据就知道了。首先，根据职业计算出资总额，这很简单：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">198</span>]: fec.contbr_occupation.value_counts()[:<span class="number">10</span>]</span><br><span class="line">Out[<span class="number">198</span>]: </span><br><span class="line">RETIRED                                   <span class="number">233990</span></span><br><span class="line">INFORMATION REQUESTED                      <span class="number">35107</span></span><br><span class="line">ATTORNEY                                   <span class="number">34286</span></span><br><span class="line">HOMEMAKER                                  <span class="number">29931</span></span><br><span class="line">PHYSICIAN                                  <span class="number">23432</span></span><br><span class="line">INFORMATION REQUESTED PER BEST EFFORTS     <span class="number">21138</span></span><br><span class="line">ENGINEER                                   <span class="number">14334</span></span><br><span class="line">TEACHER                                    <span class="number">13990</span></span><br><span class="line">CONSULTANT                                 <span class="number">13273</span></span><br><span class="line">PROFESSOR                                  <span class="number">12555</span></span><br><span class="line">Name: contbr_occupation, dtype: int64</span><br></pre></td></tr></table></figure></p>
<p>不难看出，许多职业都涉及相同的基本工作类型，或者同一样东西有多种变体。下面的代码片段可以清理一些这样的数据（将一个职业信息映射到另一个）。注意，这里巧妙地利用了dict.get，它允许没有映射关系的职业也能“通过”：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">occ_mapping = &#123;</span><br><span class="line">   <span class="string">'INFORMATION REQUESTED PER BEST EFFORTS'</span> : <span class="string">'NOT PROVIDED'</span>,</span><br><span class="line">   <span class="string">'INFORMATION REQUESTED'</span> : <span class="string">'NOT PROVIDED'</span>,</span><br><span class="line">   <span class="string">'INFORMATION REQUESTED (BEST EFFORTS)'</span> : <span class="string">'NOT PROVIDED'</span>,</span><br><span class="line">   <span class="string">'C.E.O.'</span>: <span class="string">'CEO'</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># If no mapping provided, return x</span></span><br><span class="line">f = <span class="keyword">lambda</span> x: occ_mapping.get(x, x)</span><br><span class="line">fec.contbr_occupation = fec.contbr_occupation.map(f)</span><br></pre></td></tr></table></figure></p>
<p>我对雇主信息也进行了同样的处理：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">emp_mapping = &#123;</span><br><span class="line">   <span class="string">'INFORMATION REQUESTED PER BEST EFFORTS'</span> : <span class="string">'NOT PROVIDED'</span>,</span><br><span class="line">   <span class="string">'INFORMATION REQUESTED'</span> : <span class="string">'NOT PROVIDED'</span>,</span><br><span class="line">   <span class="string">'SELF'</span> : <span class="string">'SELF-EMPLOYED'</span>,</span><br><span class="line">   <span class="string">'SELF EMPLOYED'</span> : <span class="string">'SELF-EMPLOYED'</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># If no mapping provided, return x</span></span><br><span class="line">f = <span class="keyword">lambda</span> x: emp_mapping.get(x, x)</span><br><span class="line">fec.contbr_employer = fec.contbr_employer.map(f)</span><br></pre></td></tr></table></figure></p>
<p>现在，你可以通过pivot_table根据党派和职业对数据进行聚合，然后过滤掉总出资额不足200万美元的数据：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">201</span>]: by_occupation = fec.pivot_table(<span class="string">'contb_receipt_amt'</span>,</span><br><span class="line">   .....:                                 index=<span class="string">'contbr_occupation'</span>,</span><br><span class="line">   .....:                                 columns=<span class="string">'party'</span>, aggfunc=<span class="string">'sum'</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">202</span>]: over_2mm = by_occupation[by_occupation.sum(<span class="number">1</span>) &gt; <span class="number">2000000</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">203</span>]: over_2mm</span><br><span class="line">Out[<span class="number">203</span>]: </span><br><span class="line">party                 Democrat    Republican</span><br><span class="line">contbr_occupation                           </span><br><span class="line">ATTORNEY           <span class="number">11141982.97</span>  <span class="number">7.477194e+06</span></span><br><span class="line">CEO                 <span class="number">2074974.79</span>  <span class="number">4.211041e+06</span></span><br><span class="line">CONSULTANT          <span class="number">2459912.71</span>  <span class="number">2.544725e+06</span></span><br><span class="line">ENGINEER             <span class="number">951525.55</span>  <span class="number">1.818374e+06</span></span><br><span class="line">EXECUTIVE           <span class="number">1355161.05</span>  <span class="number">4.138850e+06</span></span><br><span class="line"><span class="meta">... </span>                       ...           ...</span><br><span class="line">PRESIDENT           <span class="number">1878509.95</span>  <span class="number">4.720924e+06</span></span><br><span class="line">PROFESSOR           <span class="number">2165071.08</span>  <span class="number">2.967027e+05</span></span><br><span class="line">REAL ESTATE          <span class="number">528902.09</span>  <span class="number">1.625902e+06</span></span><br><span class="line">RETIRED            <span class="number">25305116.38</span>  <span class="number">2.356124e+07</span></span><br><span class="line">SELF-EMPLOYED        <span class="number">672393.40</span>  <span class="number">1.640253e+06</span></span><br><span class="line">[<span class="number">17</span> rows x <span class="number">2</span> columns]</span><br></pre></td></tr></table></figure></p>
<p>把这些数据做成柱状图看起来会更加清楚（’barh’表示水平柱状图，如图14-12所示）：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">205</span>]: over_2mm.plot(kind=<span class="string">'barh'</span>)</span><br></pre></td></tr></table></figure></p>
<p><img src="http://upload-images.jianshu.io/upload_images/7178691-d2254e547c6ce537.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图14-12 对各党派总出资额最高的职业"></p>
<p>你可能还想了解一下对Obama和Romney总出资额最高的职业和企业。为此，我们先对候选人进行分组，然后使用本章前面介绍的类似top的方法：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_top_amounts</span><span class="params">(group, key, n=<span class="number">5</span>)</span>:</span></span><br><span class="line">    totals = group.groupby(key)[<span class="string">'contb_receipt_amt'</span>].sum()</span><br><span class="line">    <span class="keyword">return</span> totals.nlargest(n)</span><br></pre></td></tr></table></figure></p>
<p>然后根据职业和雇主进行聚合：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">207</span>]: grouped = fec_mrbo.groupby(<span class="string">'cand_nm'</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">208</span>]: grouped.apply(get_top_amounts, <span class="string">'contbr_occupation'</span>, n=<span class="number">7</span>)</span><br><span class="line">Out[<span class="number">208</span>]: </span><br><span class="line">cand_nm        contbr_occupation    </span><br><span class="line">Obama, Barack  RETIRED                  <span class="number">25305116.38</span></span><br><span class="line">               ATTORNEY                 <span class="number">11141982.97</span></span><br><span class="line">               INFORMATION REQUESTED     <span class="number">4866973.96</span></span><br><span class="line">               HOMEMAKER                 <span class="number">4248875.80</span></span><br><span class="line">               PHYSICIAN                 <span class="number">3735124.94</span></span><br><span class="line">                                           ...     </span><br><span class="line">Romney, Mitt   HOMEMAKER                 <span class="number">8147446.22</span></span><br><span class="line">               ATTORNEY                  <span class="number">5364718.82</span></span><br><span class="line">               PRESIDENT                 <span class="number">2491244.89</span></span><br><span class="line">               EXECUTIVE                 <span class="number">2300947.03</span></span><br><span class="line">               C.E.O.                    <span class="number">1968386.11</span></span><br><span class="line">Name: contb_receipt_amt, Length: <span class="number">14</span>, dtype: float64</span><br><span class="line"></span><br><span class="line">In [<span class="number">209</span>]: grouped.apply(get_top_amounts, <span class="string">'contbr_employer'</span>, n=<span class="number">10</span>)</span><br><span class="line">Out[<span class="number">209</span>]: </span><br><span class="line">cand_nm        contbr_employer      </span><br><span class="line">Obama, Barack  RETIRED                  <span class="number">22694358.85</span></span><br><span class="line">               SELF-EMPLOYED            <span class="number">17080985.96</span></span><br><span class="line">               NOT EMPLOYED              <span class="number">8586308.70</span></span><br><span class="line">               INFORMATION REQUESTED     <span class="number">5053480.37</span></span><br><span class="line">               HOMEMAKER                 <span class="number">2605408.54</span></span><br><span class="line">                                           ...     </span><br><span class="line">Romney, Mitt   CREDIT SUISSE              <span class="number">281150.00</span></span><br><span class="line">               MORGAN STANLEY             <span class="number">267266.00</span></span><br><span class="line">               GOLDMAN SACH &amp; CO.         <span class="number">238250.00</span></span><br><span class="line">               BARCLAYS CAPITAL           <span class="number">162750.00</span></span><br><span class="line">               H.I.G. CAPITAL             <span class="number">139500.00</span></span><br><span class="line">Name: contb_receipt_amt, Length: <span class="number">20</span>, dtype: float64</span><br></pre></td></tr></table></figure></p>
<h2 id="对出资额分组"><a href="#对出资额分组" class="headerlink" title="对出资额分组"></a>对出资额分组</h2><p>还可以对该数据做另一种非常实用的分析：利用cut函数根据出资额的大小将数据离散化到多个面元中：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">210</span>]: bins = np.array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">10</span>, <span class="number">100</span>, <span class="number">1000</span>, <span class="number">10000</span>,</span><br><span class="line">   .....:                  <span class="number">100000</span>, <span class="number">1000000</span>, <span class="number">10000000</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">211</span>]: labels = pd.cut(fec_mrbo.contb_receipt_amt, bins)</span><br><span class="line"></span><br><span class="line">In [<span class="number">212</span>]: labels</span><br><span class="line">Out[<span class="number">212</span>]: </span><br><span class="line"><span class="number">411</span>         (<span class="number">10</span>, <span class="number">100</span>]</span><br><span class="line"><span class="number">412</span>       (<span class="number">100</span>, <span class="number">1000</span>]</span><br><span class="line"><span class="number">413</span>       (<span class="number">100</span>, <span class="number">1000</span>]</span><br><span class="line"><span class="number">414</span>         (<span class="number">10</span>, <span class="number">100</span>]</span><br><span class="line"><span class="number">415</span>         (<span class="number">10</span>, <span class="number">100</span>]</span><br><span class="line">             ...     </span><br><span class="line"><span class="number">701381</span>      (<span class="number">10</span>, <span class="number">100</span>]</span><br><span class="line"><span class="number">701382</span>    (<span class="number">100</span>, <span class="number">1000</span>]</span><br><span class="line"><span class="number">701383</span>        (<span class="number">1</span>, <span class="number">10</span>]</span><br><span class="line"><span class="number">701384</span>      (<span class="number">10</span>, <span class="number">100</span>]</span><br><span class="line"><span class="number">701385</span>    (<span class="number">100</span>, <span class="number">1000</span>]</span><br><span class="line">Name: contb_receipt_amt, Length: <span class="number">694282</span>, dtype: category</span><br><span class="line">Categories (<span class="number">8</span>, interval[int64]): [(<span class="number">0</span>, <span class="number">1</span>] &lt; (<span class="number">1</span>, <span class="number">10</span>] &lt; (<span class="number">10</span>, <span class="number">100</span>] &lt; (<span class="number">100</span>, <span class="number">1000</span>] &lt; (<span class="number">1</span></span><br><span class="line"><span class="number">000</span>, <span class="number">10000</span>] &lt;</span><br><span class="line">                                  (<span class="number">10000</span>, <span class="number">100000</span>] &lt; (<span class="number">100000</span>, <span class="number">1000000</span>] &lt; (<span class="number">1000000</span>,</span><br><span class="line"> <span class="number">10000000</span>]]</span><br></pre></td></tr></table></figure></p>
<p>现在可以根据候选人姓名以及面元标签对奥巴马和罗姆尼数据进行分组，以得到一个柱状图：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">213</span>]: grouped = fec_mrbo.groupby([<span class="string">'cand_nm'</span>, labels])</span><br><span class="line"></span><br><span class="line">In [<span class="number">214</span>]: grouped.size().unstack(<span class="number">0</span>)</span><br><span class="line">Out[<span class="number">214</span>]: </span><br><span class="line">cand_nm              Obama, Barack  Romney, Mitt</span><br><span class="line">contb_receipt_amt                               </span><br><span class="line">(<span class="number">0</span>, <span class="number">1</span>]                       <span class="number">493.0</span>          <span class="number">77.0</span></span><br><span class="line">(<span class="number">1</span>, <span class="number">10</span>]                    <span class="number">40070.0</span>        <span class="number">3681.0</span></span><br><span class="line">(<span class="number">10</span>, <span class="number">100</span>]                 <span class="number">372280.0</span>       <span class="number">31853.0</span></span><br><span class="line">(<span class="number">100</span>, <span class="number">1000</span>]               <span class="number">153991.0</span>       <span class="number">43357.0</span></span><br><span class="line">(<span class="number">1000</span>, <span class="number">10000</span>]              <span class="number">22284.0</span>       <span class="number">26186.0</span></span><br><span class="line">(<span class="number">10000</span>, <span class="number">100000</span>]                <span class="number">2.0</span>           <span class="number">1.0</span></span><br><span class="line">(<span class="number">100000</span>, <span class="number">1000000</span>]              <span class="number">3.0</span>           NaN</span><br><span class="line">(<span class="number">1000000</span>, <span class="number">10000000</span>]            <span class="number">4.0</span>           NaN</span><br></pre></td></tr></table></figure></p>
<p>从这个数据中可以看出，在小额赞助方面，Obama获得的数量比Romney多得多。你还可以对出资额求和并在面元内规格化，以便图形化显示两位候选人各种赞助额度的比例（见图14-13）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">216</span>]: bucket_sums = grouped.contb_receipt_amt.sum().unstack(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">217</span>]: normed_sums = bucket_sums.div(bucket_sums.sum(axis=<span class="number">1</span>), axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">218</span>]: normed_sums</span><br><span class="line">Out[<span class="number">218</span>]: </span><br><span class="line">cand_nm              Obama, Barack  Romney, Mitt</span><br><span class="line">contb_receipt_amt                               </span><br><span class="line">(<span class="number">0</span>, <span class="number">1</span>]                    <span class="number">0.805182</span>      <span class="number">0.194818</span></span><br><span class="line">(<span class="number">1</span>, <span class="number">10</span>]                   <span class="number">0.918767</span>      <span class="number">0.081233</span></span><br><span class="line">(<span class="number">10</span>, <span class="number">100</span>]                 <span class="number">0.910769</span>      <span class="number">0.089231</span></span><br><span class="line">(<span class="number">100</span>, <span class="number">1000</span>]               <span class="number">0.710176</span>      <span class="number">0.289824</span></span><br><span class="line">(<span class="number">1000</span>, <span class="number">10000</span>]             <span class="number">0.447326</span>      <span class="number">0.552674</span></span><br><span class="line">(<span class="number">10000</span>, <span class="number">100000</span>]           <span class="number">0.823120</span>      <span class="number">0.176880</span></span><br><span class="line">(<span class="number">100000</span>, <span class="number">1000000</span>]         <span class="number">1.000000</span>           NaN</span><br><span class="line">(<span class="number">1000000</span>, <span class="number">10000000</span>]       <span class="number">1.000000</span>           NaN</span><br><span class="line"></span><br><span class="line">In [<span class="number">219</span>]: normed_sums[:<span class="number">-2</span>].plot(kind=<span class="string">'barh'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="http://upload-images.jianshu.io/upload_images/7178691-77e8c8d3c784692b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="图14-13 两位候选人收到的各种捐赠额度的总额比例"></p>
<p>我排除了两个最大的面元，因为这些不是由个人捐赠的。</p>
<p>还可以对该分析过程做许多的提炼和改进。比如说，可以根据赞助人的姓名和邮编对数据进行聚合，以便找出哪些人进行了多次小额捐款，哪些人又进行了一次或多次大额捐款。我强烈建议你下载这些数据并自己摸索一下。</p>
<h2 id="根据州统计赞助信息"><a href="#根据州统计赞助信息" class="headerlink" title="根据州统计赞助信息"></a>根据州统计赞助信息</h2><p>根据候选人和州对数据进行聚合是常规操作：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">220</span>]: grouped = fec_mrbo.groupby([<span class="string">'cand_nm'</span>, <span class="string">'contbr_st'</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">221</span>]: totals = grouped.contb_receipt_amt.sum().unstack(<span class="number">0</span>).fillna(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">222</span>]: totals = totals[totals.sum(<span class="number">1</span>) &gt; <span class="number">100000</span>]</span><br><span class="line"></span><br><span class="line">In [<span class="number">223</span>]: totals[:<span class="number">10</span>]</span><br><span class="line">Out[<span class="number">223</span>]: </span><br><span class="line">cand_nm    Obama, Barack  Romney, Mitt</span><br><span class="line">contbr_st                             </span><br><span class="line">AK             <span class="number">281840.15</span>      <span class="number">86204.24</span></span><br><span class="line">AL             <span class="number">543123.48</span>     <span class="number">527303.51</span></span><br><span class="line">AR             <span class="number">359247.28</span>     <span class="number">105556.00</span></span><br><span class="line">AZ            <span class="number">1506476.98</span>    <span class="number">1888436.23</span></span><br><span class="line">CA           <span class="number">23824984.24</span>   <span class="number">11237636.60</span></span><br><span class="line">CO            <span class="number">2132429.49</span>    <span class="number">1506714.12</span></span><br><span class="line">CT            <span class="number">2068291.26</span>    <span class="number">3499475.45</span></span><br><span class="line">DC            <span class="number">4373538.80</span>    <span class="number">1025137.50</span></span><br><span class="line">DE             <span class="number">336669.14</span>      <span class="number">82712.00</span></span><br><span class="line">FL            <span class="number">7318178.58</span>    <span class="number">8338458.81</span></span><br></pre></td></tr></table></figure></p>
<p>如果对各行除以总赞助额，就会得到各候选人在各州的总赞助额比例：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">In [<span class="number">224</span>]: percent = totals.div(totals.sum(<span class="number">1</span>), axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">In [<span class="number">225</span>]: percent[:<span class="number">10</span>]</span><br><span class="line">Out[<span class="number">225</span>]: </span><br><span class="line">cand_nm    Obama, Barack  Romney, Mitt</span><br><span class="line">contbr_st                             </span><br><span class="line">AK              <span class="number">0.765778</span>      <span class="number">0.234222</span></span><br><span class="line">AL              <span class="number">0.507390</span>      <span class="number">0.492610</span></span><br><span class="line">AR              <span class="number">0.772902</span>      <span class="number">0.227098</span></span><br><span class="line">AZ              <span class="number">0.443745</span>      <span class="number">0.556255</span></span><br><span class="line">CA              <span class="number">0.679498</span>      <span class="number">0.320502</span></span><br><span class="line">CO              <span class="number">0.585970</span>      <span class="number">0.414030</span></span><br><span class="line">CT              <span class="number">0.371476</span>      <span class="number">0.628524</span></span><br><span class="line">DC              <span class="number">0.810113</span>      <span class="number">0.189887</span></span><br><span class="line">DE              <span class="number">0.802776</span>      <span class="number">0.197224</span></span><br><span class="line">FL              <span class="number">0.467417</span>      <span class="number">0.532583</span></span><br></pre></td></tr></table></figure></p>
<p>#14.6 总结</p>
<p>我们已经完成了正文的最后一章。附录中有一些额外的内容，可能对你有用。</p>
<p>本书第一版出版已经有5年了，Python已经成为了一个流行的、广泛使用的数据分析语言。你从本书中学到的方法，在相当长的一段时间都是可用的。我希望本书介绍的工具和库对你的工作有用。</p>

      
    </div>
    
    
    
	
	  <div>
        
        <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">----------<i class="fa fa-paw"></i> End 谢谢您的阅读----------</div>
    
</div>
        
      </div>
	<div>
      
        
      
    </div>

    
	
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/数据分析/" rel="tag"><i class="fa fa-tag"></i> 数据分析</a>
          
            <a href="/tags/Python教程/" rel="tag"><i class="fa fa-tag"></i> Python教程</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/01/20/第13章 Python建模库介绍/" rel="next" title="第13章 Python建模库介绍">
                <i class="fa fa-chevron-left"></i> 第13章 Python建模库介绍
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/01/22/附录B 更多关于IPython的内容（完）/" rel="prev" title="附录B 更多关于IPython的内容">
                附录B 更多关于IPython的内容 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="lv-container" data-id="city" data-uid="MTAyMC80MDE5My8xNjcyMA=="></div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.jpg"
                alt="Janet" />
            
              <p class="site-author-name" itemprop="name">Janet</p>
              <p class="site-description motion-element" itemprop="description">数据分析，旅游攻略，心情随笔</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">18</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">6</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/JanetCheng01" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://blog.csdn.net/Claire_Cheng" target="_blank" title="CSDN">
                      
                        <i class="fa fa-fw fa-copyright"></i>CSDN</a>
                  </span>
                
            </div>
          

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-inline">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                Links
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="https://github.com/iissnan/hexo-theme-next/blob/master/README.cn.md" title="Next主题" target="_blank">Next主题</a>
                  </li>
                
              </ul>
            </div>
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#用pandas对时区进行计数"><span class="nav-number">1.</span> <span class="nav-text">用pandas对时区进行计数</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#14-2-MovieLens-1M数据集"><span class="nav-number"></span> <span class="nav-text">14.2 MovieLens 1M数据集</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#计算评分分歧"><span class="nav-number">1.</span> <span class="nav-text">计算评分分歧</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#14-3-1880-2010年间全美婴儿姓名"><span class="nav-number"></span> <span class="nav-text">14.3 1880-2010年间全美婴儿姓名</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#分析命名趋势"><span class="nav-number">1.</span> <span class="nav-text">分析命名趋势</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#评估命名多样性的增长"><span class="nav-number">2.</span> <span class="nav-text">评估命名多样性的增长</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#“最后一个字母”的变革"><span class="nav-number">3.</span> <span class="nav-text">“最后一个字母”的变革</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#变成女孩名字的男孩名字（以及相反的情况）"><span class="nav-number">4.</span> <span class="nav-text">变成女孩名字的男孩名字（以及相反的情况）</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#14-4-USDA食品数据库"><span class="nav-number"></span> <span class="nav-text">14.4 USDA食品数据库</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#14-5-2012联邦选举委员会数据库"><span class="nav-number"></span> <span class="nav-text">14.5 2012联邦选举委员会数据库</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#根据职业和雇主统计赞助信息"><span class="nav-number">1.</span> <span class="nav-text">根据职业和雇主统计赞助信息</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#对出资额分组"><span class="nav-number">2.</span> <span class="nav-text">对出资额分组</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#根据州统计赞助信息"><span class="nav-number">3.</span> <span class="nav-text">根据州统计赞助信息</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-star"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Janet</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Site words total count&#58;</span>
    
    <span title="Site words total count">147k</span>
  
</div>





        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
          <span id="scrollpercent"><span>0</span>%</span>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  




  
    <script type="text/javascript">
      (function(d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') { return; }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;
        e.parentNode.insertBefore(j, e);
      })(document, 'script');
    </script>
  










  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  

  

  

<script src="/live2dw/lib/L2Dwidget.min.js?0c58a1486de42ac6cc1c59c7d98ae887"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","model":{"jsonPath":"live2d-widget-model-wanko"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"log":false,"tagMode":false});</script></body>
</html>
